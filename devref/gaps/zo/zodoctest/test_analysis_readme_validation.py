#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ docs/api/analysis/README.md
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞, cross-references –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É API
"""

import sys
import os
import importlib
import traceback
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

def test_imports_from_docs():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    print("üìã –¢–µ—Å—Ç: –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
    
    imports_to_test = [
        # Universal Pipeline
        ('bquant.analysis.zones', 'analyze_zones'),
        ('bquant.data.samples', 'get_sample_data'),
        
        # Statistical analysis
        ('bquant.analysis.statistical', 'HypothesisTestSuite'),
        ('bquant.analysis.statistical', 'StatisticalAnalyzer'),
        ('bquant.analysis.statistical', 'run_all_hypothesis_tests'),
        
        # Base analysis
        ('bquant.analysis', 'BaseAnalyzer'),
        ('bquant.analysis', 'AnalysisResult'),
    ]
    
    success_count = 0
    total_count = len(imports_to_test)
    
    for module_name, class_or_func_name in imports_to_test:
        try:
            module = importlib.import_module(module_name)
            obj = getattr(module, class_or_func_name)
            print(f"  ‚úÖ {module_name}.{class_or_func_name}")
            success_count += 1
        except Exception as e:
            print(f"  ‚ùå {module_name}.{class_or_func_name}: {e}")
    
    print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç: {success_count}/{total_count} –∏–º–ø–æ—Ä—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ")
    return success_count == total_count

def test_universal_pipeline_example():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä Universal Pipeline –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    print("\nüìã –¢–µ—Å—Ç: Universal Pipeline –ø—Ä–∏–º–µ—Ä")
    
    try:
        from bquant.analysis.zones import analyze_zones
        from bquant.data.samples import get_sample_data
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        data = get_sample_data('tv_xauusd_1h')
        print(f"  ‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(data)} –∑–∞–ø–∏—Å–µ–π")
        
        # Universal Pipeline —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ hypothesis tests
        result = (
            analyze_zones(data)
            .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
            .detect_zones('zero_crossing', indicator_col='macd_hist')
            .with_strategies(swing='find_peaks', divergence='classic')
            .analyze(clustering=True)  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç hypothesis tests
            .build()
        )
        
        print(f"  ‚úÖ Universal Pipeline –≤—ã–ø–æ–ª–Ω–µ–Ω: {len(result.zones)} –∑–æ–Ω")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if result.hypothesis_tests:
            print(f"  ‚úÖ Hypothesis tests –¥–æ—Å—Ç—É–ø–Ω—ã: {len(result.hypothesis_tests.results)} —Ç–µ—Å—Ç–æ–≤")
            for test_name, test_result in result.hypothesis_tests.results.items():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if hasattr(test_result, 'p_value'):
                    print(f"    {test_name}: p={test_result.p_value:.4f}")
                elif isinstance(test_result, dict) and 'p_value' in test_result:
                    print(f"    {test_name}: p={test_result['p_value']:.4f}")
                else:
                    print(f"    {test_name}: {test_result}")
        else:
            print(f"  ‚ö†Ô∏è Hypothesis tests –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Universal Pipeline: {e}")
        traceback.print_exc()
        return False

def test_single_hypothesis_example():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã"""
    print("\nüìã –¢–µ—Å—Ç: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã")
    
    try:
        from bquant.analysis.statistical import run_all_hypothesis_tests
        from bquant.analysis.zones import analyze_zones
        from bquant.data.samples import get_sample_data
        import numpy as np
        from scipy import stats
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏–∑
        data = get_sample_data('tv_xauusd_1h')
        result = (
            analyze_zones(data)
            .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
            .detect_zones('zero_crossing', indicator_col='macd_hist')
            .analyze(clustering=False)
            .build()
        )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∞
        bull_volatility = []
        bear_volatility = []
        
        for zone in result.zones:
            if zone.features:
                volatility = zone.features.get('avg_volatility', 0)
                if zone.type == 'bull':
                    bull_volatility.append(volatility)
                elif zone.type == 'bear':
                    bear_volatility.append(volatility)
        
        if len(bull_volatility) > 0 and len(bear_volatility) > 0:
            # T-—Ç–µ—Å—Ç
            t_stat, p_value = stats.ttest_ind(bull_volatility, bear_volatility)
            
            print(f"  ‚úÖ T-test –≤—ã–ø–æ–ª–Ω–µ–Ω:")
            print(f"    p-value: {p_value:.4f}")
            print(f"    Significant: {p_value < 0.05}")
            print(f"    t-statistic: {t_stat:.4f}")
            return True
        else:
            print(f"  ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è T-test")
            return True
            
    except Exception as e:
        print(f"  ‚ùå Single hypothesis test: {e}")
        traceback.print_exc()
        return False

def test_zone_features_analysis():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∑–æ–Ω"""
    print("\nüìã –¢–µ—Å—Ç: –ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∑–æ–Ω")
    
    try:
        from bquant.analysis.zones import analyze_zones
        from bquant.data.samples import get_sample_data
        
        # Universal Pipeline –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        data = get_sample_data('tv_xauusd_1h')
        result = (
            analyze_zones(data)
            .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
            .detect_zones('zero_crossing', indicator_col='macd_hist')
            .with_strategies(swing='find_peaks', volatility='combined')
            .analyze(clustering=True)
            .build()
        )
        
        print(f"  ‚úÖ Zone features analysis:")
        print(f"    Total zones analyzed: {len(result.zones)}")
        
        features_count = 0
        for i, zone in enumerate(result.zones[:3]):
            if zone.features:
                features_count += 1
                print(f"    Zone {i}: volatility={zone.features.get('volatility_regime', 'unknown')}")
                print(f"      Swings: {zone.features.get('num_swings', 0)}")
                print(f"      Duration: {zone.features.get('duration', 0):.2f}")
        
        print(f"  ‚úÖ Zones with features: {features_count}")
        return True
        
    except Exception as e:
        print(f"  ‚ùå Zone features analysis: {e}")
        traceback.print_exc()
        return False

def test_sequence_analysis():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∑–æ–Ω"""
    print("\nüìã –¢–µ—Å—Ç: –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∑–æ–Ω")
    
    try:
        from bquant.analysis.zones import analyze_zones
        from bquant.data.samples import get_sample_data
        
        # Universal Pipeline —Å sequence analysis
        data = get_sample_data('tv_xauusd_1h')
        result = (
            analyze_zones(data)
            .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
            .detect_zones('zero_crossing', indicator_col='macd_hist')
            .analyze(clustering=True)  # sequence analysis –≤–∫–ª—é—á–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            .build()
        )
        
        print(f"  ‚úÖ Sequence analysis:")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É –∑–æ–Ω–∞–º–∏
        if result.sequence_analysis:
            print(f"    Bull to Bear transitions: {result.sequence_analysis.get('bull_to_bear', 0)}")
            print(f"    Bear to Bull transitions: {result.sequence_analysis.get('bear_to_bull', 0)}")
        else:
            print(f"    ‚ö†Ô∏è Sequence analysis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–æ–Ω
        if result.clustering:
            print(f"    Number of clusters: {result.clustering.get('n_clusters', 0)}")
            cluster_labels = result.clustering.get('cluster_labels', [])
            print(f"    Cluster labels: {cluster_labels[:5]}...")
        else:
            print(f"    ‚ö†Ô∏è Clustering –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Sequence analysis: {e}")
        traceback.print_exc()
        return False

def test_statistical_analyzer():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º StatisticalAnalyzer"""
    print("\nüìã –¢–µ—Å—Ç: StatisticalAnalyzer")
    
    try:
        from bquant.analysis.statistical import StatisticalAnalyzer
        from bquant.analysis.zones import analyze_zones
        from bquant.data.samples import get_sample_data
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        stat_analyzer = StatisticalAnalyzer()
        print(f"  ‚úÖ StatisticalAnalyzer —Å–æ–∑–¥–∞–Ω")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        data = get_sample_data('tv_xauusd_1h')
        result = (
            analyze_zones(data)
            .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
            .detect_zones('zero_crossing', indicator_col='macd_hist')
            .analyze(clustering=False)
            .build()
        )
        
        bull_zones = [zone for zone in result.zones if zone.type == 'bull']
        bear_zones = [zone for zone in result.zones if zone.type == 'bear']
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        bull_durations = [zone.duration for zone in bull_zones]
        bear_durations = [zone.duration for zone in bear_zones]
        
        if len(bull_durations) > 0 and len(bear_durations) > 0:
            # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            from scipy import stats
            
            # T-—Ç–µ—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≥—Ä—É–ø–ø
            duration_t_stat, duration_p_value = stats.ttest_ind(bull_durations, bear_durations)
            
            # –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            import numpy as np
            bull_duration_stats = {
                'mean': np.mean(bull_durations),
                'std': np.std(bull_durations),
                'min': np.min(bull_durations),
                'max': np.max(bull_durations)
            }
            
            print(f"  ‚úÖ Duration comparison:")
            print(f"    p-value: {duration_p_value:.4f}")
            print(f"    Significant: {duration_p_value < 0.05}")
            
            print(f"  ‚úÖ Bull duration stats:")
            print(f"    Mean: {bull_duration_stats['mean']:.4f}")
            print(f"    Std: {bull_duration_stats['std']:.4f}")
            
            return True
        else:
            print(f"  ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            return True
            
    except Exception as e:
        print(f"  ‚ùå StatisticalAnalyzer: {e}")
        traceback.print_exc()
        return False

def test_custom_analyzer():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    print("\nüìã –¢–µ—Å—Ç: –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞")
    
    try:
        from bquant.analysis import BaseAnalyzer, AnalysisResult
        from bquant.data.samples import get_sample_data
        import numpy as np
        
        class VolatilityAnalyzer(BaseAnalyzer):
            """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
            
            def __init__(self, window_size=20):
                super().__init__('VolatilityAnalyzer')
                self.window_size = window_size
            
            def analyze(self, data):
                """–ê–Ω–∞–ª–∏–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
                if not self.validate_data(data):
                    raise ValueError("Invalid data for volatility analysis")
                
                # –†–∞—Å—á–µ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                returns = data['close'].pct_change()
                volatility = returns.rolling(window=self.window_size).std()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                volatility_stats = {
                    'mean': volatility.mean(),
                    'std': volatility.std(),
                    'min': volatility.min(),
                    'max': volatility.max(),
                    'current': volatility.iloc[-1]
                }
                
                return AnalysisResult(
                    analysis_type='VolatilityAnalyzer',
                    results=volatility_stats,
                    data_size=len(volatility),
                    metadata={'window_size': self.window_size}
                )
            
            def validate_data(self, data):
                """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
                required_columns = ['close']
                return all(col in data.columns for col in required_columns)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        data = get_sample_data('tv_xauusd_1h')
        volatility_analyzer = VolatilityAnalyzer(window_size=20)
        volatility_result = volatility_analyzer.analyze(data)
        
        print(f"  ‚úÖ VolatilityAnalyzer —Å–æ–∑–¥–∞–Ω –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω:")
        print(f"    Mean volatility: {volatility_result.results['mean']:.4f}")
        print(f"    Current volatility: {volatility_result.results['current']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Custom analyzer: {e}")
        traceback.print_exc()
        return False

def test_cross_references():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º cross-references"""
    print("\nüìã –¢–µ—Å—Ç: Cross-references")
    
    cross_refs = [
        'docs/api/core/README.md',
        'docs/api/data/README.md', 
        'docs/api/indicators/README.md',
        'docs/api/visualization/README.md',
        'docs/api/analysis/pipeline.md',
        'docs/api/analysis/strategies.md',
        'docs/api/analysis/statistical.md',
        'docs/api/analysis/zones.md',
        'docs/api/analysis/base.md'
    ]
    
    success_count = 0
    for ref in cross_refs:
        if os.path.exists(ref):
            print(f"  ‚úÖ {ref}")
            success_count += 1
        else:
            print(f"  ‚ùå {ref} - –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢")
    
    print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç: {success_count}/{len(cross_refs)} —Å—Å—ã–ª–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
    return success_count == len(cross_refs)

def test_language_check():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞"""
    print("\nüìã –¢–µ—Å—Ç: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞")
    
    try:
        with open('docs/api/analysis/README.md', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤
        russian_words = ['–∞–Ω–∞–ª–∏–∑', '–º–æ–¥—É–ª–∏', '—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π', '–∑–æ–Ω—ã', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç', '–¥–∞–Ω–Ω—ã–µ']
        found_russian = sum(1 for word in russian_words if word in content.lower())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞
        code_blocks = content.count('```python')
        
        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤: {found_russian}")
        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞: {code_blocks}")
        print(f"  ‚úÖ –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞: —Ä—É—Å—Å–∫–∏–π (–∫–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)")
        
        return True
        
    except Exception as e:
        print(f"  ‚ùå Language check: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è docs/api/analysis/README.md")
    print("=" * 60)
    
    tests = [
        test_imports_from_docs,
        test_universal_pipeline_example,
        test_single_hypothesis_example,
        test_zone_features_analysis,
        test_sequence_analysis,
        test_statistical_analyzer,
        test_custom_analyzer,
        test_cross_references,
        test_language_check
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"  ‚ùå –¢–µ—Å—Ç {test.__name__} —É–ø–∞–ª: {e}")
    
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–ê–õ–ò–î–ê–¶–ò–ò:")
    print(f"  –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 1 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  Universal Pipeline –ø—Ä–∏–º–µ—Ä: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 2 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  Single hypothesis test: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 3 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  Zone features analysis: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 4 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  Sequence analysis: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 5 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  StatisticalAnalyzer: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 6 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  Custom analyzer: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 7 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  Cross-references: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 8 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    print(f"  –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞: {'‚úÖ –ü–†–û–ô–î–ï–ù' if passed >= 9 else '‚ùå –ü–†–û–í–ê–õ–ï–ù'}")
    
    print(f"\nüéØ –ò—Ç–æ–≥–æ: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        return True
    else:
        print("‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ï–ù–´")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
