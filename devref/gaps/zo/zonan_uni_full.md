# Universal Zone Analysis - Full Pipeline Implementation Plan

**–í–µ—Ä—Å–∏—è:** 1.0  
**–î–∞—Ç–∞:** 2025-10-20  
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞  
**–¶–µ–ª—å:** –û–±–Ω–æ–≤–∏—Ç—å research notebooks –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è –í–°–ï–• –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π v2.1 universal architecture

---

## üìö Context & References

**–ë–∞–∑–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:**
- **[zonan.md](zonan.md)** - –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω Stage 2.4 (lines 3802-3998)
- **[zouni_v2.md](zouni_v2.md)** - v2.1 Architecture (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ features)
- **[zonan_v2.md](zonan_v2.md)** - –¢–µ–∫—É—â–∏–π execution plan

**–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:**
- ‚úÖ Detection pipeline –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç–∞–µ—Ç (02_ind_macd.py, 03_zones_universal.py)
- ‚ùå **Analysis pipeline (features, clustering, statistical) –ù–ï –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω**
- ‚ùå **Advanced features –ù–ï –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è –≤ notebooks**

---

## üéØ Executive Summary

### –ü—Ä–æ–±–ª–µ–º–∞

**2 –∏–∑ 3 notebooks —Ä–∞–±–æ—Ç–∞—é—Ç, –ù–û:**

1. **03_zones_universal.py** (412 lines)
   - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ **detection** (`.build()` –±–µ–∑ `.analyze()`)
   - –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ –≤ ZoneFeaturesAnalyzer" (–ë–ê–ì –£–ñ–ï –ò–°–ü–†–ê–í–õ–ï–ù –≤ v2.1!)
   - –ù–ï –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç features, clustering, statistical tests
   - **GAP:** –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å v2.1 (universal features) –Ω–µ –ø–æ–∫–∞–∑–∞–Ω–∞

2. **03_analysis_new_features.py** (693 lines)
   - –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ò–ú–ï–ù–ù–û —Ç–µ features, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ 03_zones_universal.py
   - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞—Ä—ã–π API (`macd_analyzer._zone_to_dict()` - –º–µ—Ç–æ–¥ —É–¥–∞–ª–µ–Ω)
   - **BROKEN:** Step 1 OK, Steps 2-10 fail (AttributeError)
   - **GAP:** Advanced features (swing, divergence, volume, volatility, regression, validation) –ù–ï —Ä–∞–±–æ—Ç–∞—é—Ç

### –†–µ—à–µ–Ω–∏–µ

**–ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±–æ–∏—Ö notebooks –¥–ª—è v2.1:**

1. **03_zones_universal.py** - BASE full pipeline
   - –î–æ–±–∞–≤–∏—Ç—å `.analyze(clustering=True, ...)` –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
   - –ü–æ–∫–∞–∑–∞—Ç—å features extraction (shape, volume, volatility)
   - –ü–æ–∫–∞–∑–∞—Ç—å clustering results
   - –ü–æ–∫–∞–∑–∞—Ç—å statistical tests & sequence analysis
   - –£–¥–∞–ª–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ"
   - **–¶–µ–ª—å:** –î–æ–∫–∞–∑–∞—Ç—å v2.1 universality

2. **03_analysis_new_features.py** - ADVANCED features testing
   - –û–±–Ω–æ–≤–∏—Ç—å –Ω–∞ v2.1 universal API
   - –ó–∞–º–µ–Ω–∏—Ç—å `_zone_to_dict()` –Ω–∞ `zone.features` –∏–ª–∏ –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤
   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å swing strategies (ZigZag, FindPeaks, PivotPoints)
   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å divergence detection
   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å volume/volatility analysis
   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å regression & validation
   - **–¶–µ–ª—å:** Comprehensive testing –≤—Å–µ—Ö analytical strategies

---

## üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –ø–æ —ç—Ç–∞–ø–∞–º

---

### **–≠–¢–ê–ü 1: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ 03_zones_universal.py - Full Analysis Pipeline**

**–§–∞–π–ª:** `research/notebooks/03_zones_universal.py` (412 lines ‚Üí ~550 lines)  
**–í—Ä–µ–º—è:** ~40-50 –º–∏–Ω—É—Ç  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** ‚≠ê‚≠ê‚≠ê CRITICAL

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.1: Step 5 –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç features

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (lines 219-253):**
```python
nb.step("Step 5: Zone Statistics Deep Dive")

# –¢–æ–ª—å–∫–æ –±–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
durations = [z.duration for z in result_preset.zones]
nb.log(f"  –°—Ä–µ–¥–Ω—è—è: {np.mean(durations):.2f} –±–∞—Ä–æ–≤")
# ...
# –ë–ï–ó features! ‚ùå
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.step("Step 5: Full Analysis Pipeline - Feature Extraction")

nb.info("v2.1 UNIVERSALITY PROOF: Features work for ALL indicators!")

# 5.1: MACD —Å –ø–æ–ª–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
result_macd_full = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=True,
        n_clusters=3,
        swing_strategy='find_peaks'  # v2.1: swing strategies —Ä–∞–±–æ—Ç–∞—é—Ç
    )
    .build()
)

# –ü–æ–∫–∞–∑–∞—Ç—å features –ø–µ—Ä–≤–æ–π –∑–æ–Ω—ã
if result_macd_full.zones:
    zone = result_macd_full.zones[0]
    
    nb.log("Feature extraction –¥–ª—è MACD:")
    if zone.features:
        # Shape metrics
        nb.log(f"  Shape: skewness={zone.features.get('skewness', 'N/A'):.3f}")
        nb.log(f"  Shape: kurtosis={zone.features.get('kurtosis', 'N/A'):.3f}")
        
        # Volume metrics
        if 'volume_spike_ratio' in zone.features:
            nb.log(f"  Volume: spike_ratio={zone.features['volume_spike_ratio']:.3f}")
        if 'volume_indicator_corr' in zone.features:  # v2.1: renamed from volume_macd_corr
            nb.log(f"  Volume: volume_indicator_corr={zone.features['volume_indicator_corr']:.3f}")
        
        # Volatility metrics
        if 'volatility_expansion' in zone.features:
            nb.log(f"  Volatility: expansion={zone.features['volatility_expansion']:.3f}")
        
        # Divergence metrics
        if 'has_classic_divergence' in zone.features:
            nb.log(f"  Divergence: classic={zone.features['has_classic_divergence']}")
    
    # indicator_context inspection
    ctx = zone.indicator_context
    nb.log(f"  indicator_context: {ctx['detection_indicator']} (v2.1 self-describing)")

# 5.2: RSI —Å –ø–æ–ª–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º (PROOF OF UNIVERSALITY!)
result_rsi_full = (
    analyze_zones(df)
    .with_indicator('pandas_ta', 'rsi', length=14)
    .detect_zones('threshold', indicator_col='RSI_14', upper_threshold=70, lower_threshold=30)
    .analyze(
        clustering=True,
        n_clusters=2,
        swing_strategy='find_peaks'  # v2.1: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å RSI!
    )
    .build()
)

nb.success(f"RSI zones: {len(result_rsi_full.zones)} (—Å features!)")

if result_rsi_full.zones:
    zone = result_rsi_full.zones[0]
    if zone.features:
        nb.log(f"  RSI features extracted: {list(zone.features.keys())[:5]}...")
        nb.log(f"  indicator_context: {zone.indicator_context['detection_indicator']}")
        nb.success("‚úÖ PROOF: Features work for RSI (not just MACD)!")

# 5.3: AO —Å –ø–æ–ª–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
result_ao_full = (
    analyze_zones(df)
    .with_indicator('pandas_ta', 'ao', fast=5, slow=34)
    .detect_zones('zero_crossing', indicator_col='AO_5_34')
    .analyze(clustering=True, n_clusters=2)
    .build()
)

nb.success(f"AO zones: {len(result_ao_full.zones)} (—Å features!)")
nb.success("‚úÖ PROOF: Universal features work for MACD, RSI, AO!")
```

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `.analyze()` –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (–Ω–µ —Ç–æ–ª—å–∫–æ MACD)
- –ü–æ–∫–∞–∑–∞—Ç—å extracted features –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
- –ü–æ–∫–∞–∑–∞—Ç—å `volume_indicator_corr` (v2.1 renamed field)
- –ü–æ–∫–∞–∑–∞—Ç—å `indicator_context` inspection
- –£–¥–∞–ª–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ"

**–°—Å—ã–ª–∫–∏ –Ω–∞ spec:**
- zouni_v2.md Phase 1 Task 1.6 (ZoneFeaturesAnalyzer universality)
- zouni_v2.md Phase 1 Task 1.5 (volume_indicator_corr)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.2: Clustering –Ω–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è

**–¢–µ–∫—É—â–∏–π –∫–æ–¥:**
```python
# –í—Å–µ .build() –ë–ï–ó .analyze() ‚Üí NO clustering ‚ùå
result = analyze_zones(df).with_indicator(...).detect_zones(...).build()
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.substep("5.4: Clustering Analysis")

nb.info("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–æ–Ω –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏:")

# Clustering –¥–ª—è MACD
if result_macd_full.clustering:
    clusters = result_macd_full.clustering
    
    nb.log(f"  –ö–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(set(clusters.values()))}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–æ–Ω –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
    cluster_counts = {}
    for zone_id, cluster_id in clusters.items():
        cluster_counts[cluster_id] = cluster_counts.get(cluster_id, 0) + 1
    
    nb.info("  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
    for cluster_id, count in sorted(cluster_counts.items()):
        nb.log(f"    Cluster {cluster_id}: {count} –∑–æ–Ω")
    
    # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    for cluster_id in sorted(set(clusters.values())):
        zones_in_cluster = [z for z in result_macd_full.zones if clusters.get(z.zone_id) == cluster_id]
        
        if zones_in_cluster:
            avg_duration = np.mean([z.duration for z in zones_in_cluster])
            types = [z.type for z in zones_in_cluster]
            
            nb.log(f"    Cluster {cluster_id}:")
            nb.log(f"      –ó–æ–Ω: {len(zones_in_cluster)}")
            nb.log(f"      Avg duration: {avg_duration:.1f} bars")
            nb.log(f"      Types: {set(types)}")
```

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- –í–∫–ª—é—á–∏—Ç—å `clustering=True` –≤ `.analyze()`
- –ü–æ–∫–∞–∑–∞—Ç—å `result.clustering` dict
- –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–æ–Ω –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
- –ü–æ–∫–∞–∑–∞—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.3: Statistical tests –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è

**–¢–µ–∫—É—â–∏–π –∫–æ–¥:**
```python
# –ù–ï–¢ usage HypothesisTestSuite ‚ùå
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.substep("5.5: Statistical Hypothesis Tests")

nb.info("–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –¥–ª—è –∑–æ–Ω MACD:")

if result_macd_full.hypothesis_tests:
    tests = result_macd_full.hypothesis_tests
    
    nb.log(f"  Tests executed: {tests.data_size if hasattr(tests, 'data_size') else 'N/A'}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
    if hasattr(tests, 'results'):
        for test_name, test_result in tests.results.items():
            if test_result and hasattr(test_result, 'p_value'):
                nb.log(f"  {test_name}:")
                nb.log(f"    p-value: {test_result.p_value:.4f}")
                nb.log(f"    significant: {test_result.p_value < 0.05}")
            elif test_result and hasattr(test_result, 'test_statistic'):
                nb.log(f"  {test_name}:")
                nb.log(f"    statistic: {test_result.test_statistic:.4f}")
    
    nb.info("  Hypothesis tests help validate zone significance")
else:
    nb.warning("  Insufficient data for hypothesis tests (need more zones)")
```

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- –ü–æ–∫–∞–∑–∞—Ç—å `result.hypothesis_tests` (AnalysisResult object)
- –ò–∑–≤–ª–µ—á—å p-values –∏ test statistics
- –û–±—ä—è—Å–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.4: Sequence analysis –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è

**–¢–µ–∫—É—â–∏–π –∫–æ–¥:**
```python
# –ù–ï–¢ usage ZoneSequenceAnalyzer ‚ùå
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.substep("5.6: Sequence Analysis")

nb.info("–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:")

if result_macd_full.sequences:
    seq = result_macd_full.sequences
    
    nb.log(f"  Total zones analyzed: {len(result_macd_full.zones)}")
    
    # Transitions
    if hasattr(seq, 'transitions') and seq.transitions:
        nb.info("  Transitions (zone type changes):")
        for trans_type, count in seq.transitions.items():
            nb.log(f"    {trans_type}: {count}")
    
    # Patterns
    if hasattr(seq, 'patterns'):
        nb.info(f"  Patterns found: {len(seq.patterns) if seq.patterns else 0}")
        
        if seq.patterns:
            for pattern in seq.patterns[:3]:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 3
                nb.log(f"    Pattern: {pattern.get('type', 'N/A')} (length: {pattern.get('length', 'N/A')})")
    
    nb.info("  Sequence analysis helps identify zone patterns and trading regimes")
else:
    nb.warning("  No sequence analysis results")
```

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- –ü–æ–∫–∞–∑–∞—Ç—å `result.sequences` object
- –ü–æ–∫–∞–∑–∞—Ç—å transitions (bull‚Üíbear, bear‚Üíbull)
- –ü–æ–∫–∞–∑–∞—Ç—å detected patterns

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.5: Step 9 –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç feature comparison

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (lines 434-492):**
```python
nb.step("Step 9: Other Indicators - Detection Examples")

# –¢–æ–ª—å–∫–æ detection, –ë–ï–ó analyze() ‚ùå
result_rsi = analyze_zones(df).with_indicator(...).detect_zones(...).build()
result_ao = analyze_zones(df).with_indicator(...).detect_zones(...).build()

# –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ö–û–õ–ò–ß–ï–°–¢–í–û –∑–æ–Ω
nb.log(f"RSI: {len(result_rsi.zones)} zones")
nb.log(f"AO: {len(result_ao.zones)} zones")
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.step("Step 9: Multiple Indicators - Feature Comparison")

nb.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ features –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤:")

# RSI —Å full analysis
result_rsi_analyzed = (
    analyze_zones(df)
    .with_indicator('pandas_ta', 'rsi', length=14)
    .detect_zones('threshold', indicator_col='RSI_14', upper_threshold=70, lower_threshold=30)
    .analyze(clustering=True, n_clusters=2)
    .build()
)

# AO —Å full analysis
result_ao_analyzed = (
    analyze_zones(df)
    .with_indicator('pandas_ta', 'ao', fast=5, slow=34)
    .detect_zones('zero_crossing', indicator_col='AO_5_34')
    .analyze(clustering=True, n_clusters=2)
    .build()
)

# –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
nb.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ zones –∏ features:")
nb.log(f"{'Indicator':<15} {'Zones':<10} {'Avg Duration':<15} {'Has Features':<15}")
nb.log("-" * 60)

for name, result in [('MACD', result_macd_full), ('RSI', result_rsi_analyzed), ('AO', result_ao_analyzed)]:
    zones_count = len(result.zones)
    avg_duration = np.mean([z.duration for z in result.zones]) if result.zones else 0
    has_features = any(z.features for z in result.zones)
    
    nb.log(f"{name:<15} {zones_count:<10} {avg_duration:<15.1f} {has_features!s:<15}")

# Zone overlap analysis
nb.substep("9.1: Zone Overlap Analysis")

# –ù–∞–π—Ç–∏ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
macd_periods = [(z.start_index, z.end_index) for z in result_macd_full.zones]
rsi_periods = [(z.start_index, z.end_index) for z in result_rsi_analyzed.zones]

overlaps = 0
for m_start, m_end in macd_periods:
    for r_start, r_end in rsi_periods:
        if not (m_end < r_start or r_end < m_start):  # Overlap check
            overlaps += 1
            break

nb.log(f"  MACD zones: {len(macd_periods)}")
nb.log(f"  RSI zones: {len(rsi_periods)}")
nb.log(f"  Overlapping zones: {overlaps}")
nb.log(f"  Overlap ratio: {overlaps / max(len(macd_periods), 1) * 100:.1f}%")

# Consensus signals
nb.substep("9.2: Consensus Signals")

consensus_count = 0
if result_macd_full.zones and result_rsi_analyzed.zones:
    # –ù–∞–π—Ç–∏ –∑–æ–Ω—ã –≥–¥–µ –æ–±–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ —Å–æ–≥–ª–∞—Å–Ω—ã
    for mz in result_macd_full.zones:
        for rz in result_rsi_analyzed.zones:
            # Overlap + same type = consensus
            if (not (mz.end_index < rz.start_index or rz.end_index < mz.start_index) and
                mz.type == rz.type):
                consensus_count += 1
                break

nb.log(f"  Consensus signals (MACD + RSI agree): {consensus_count}")
nb.log(f"  Use for: Higher confidence trades")

nb.success("‚úÖ Multi-indicator feature comparison complete!")
```

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- `.analyze()` –¥–ª—è RSI –∏ AO (–Ω–µ —Ç–æ–ª—å–∫–æ detection)
- –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ features
- Zone overlap analysis
- Consensus signals (–≥–¥–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–æ–≥–ª–∞—Å–Ω—ã)

**–°—Å—ã–ª–∫–∏:**
- zonan.md lines 3956-3960 (Multiple Indicators Comparison spec)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.6: Edge cases –Ω–µ —Ç–µ—Å—Ç–∏—Ä—É—é—Ç—Å—è

**–¢–µ–∫—É—â–∏–π –∫–æ–¥:**
```python
# Step 9: Edge Cases - –û–¢–°–£–¢–°–¢–í–£–ï–¢ ‚ùå
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π Step 11 (–∏–ª–∏ –≤—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ Step 6)
nb.step("Step 11: Edge Cases & Error Handling")

nb.info("Graceful handling edge cases:")

nb.substep("11.1: Small Dataset (< 50 bars)")

small_df = df.head(30)
result_small = (
    analyze_zones(small_df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(clustering=False)
    .build()
)

nb.log(f"  Small dataset (30 bars): {len(result_small.zones)} zones detected")
nb.log(f"  Pipeline works with minimal data ‚úÖ")

nb.substep("11.2: No Zones Detected")

# –û—á–µ–Ω—å —Å—Ç—Ä–æ–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Üí –Ω–µ—Ç –∑–æ–Ω
result_no_zones = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('threshold', indicator_col='macd_hist', 
                  upper_threshold=100, lower_threshold=-100,  # Impossible thresholds
                  min_duration=1000)  # Very long duration
    .analyze(clustering=False)
    .build()
)

nb.log(f"  No zones case: {len(result_no_zones.zones)} zones")
nb.log(f"  Pipeline handles gracefully (no crash) ‚úÖ")

nb.substep("11.3: Missing Indicator Column")

with nb.error_handling("Missing column test", critical=False):
    try:
        result_missing = (
            analyze_zones(df)
            .detect_zones('zero_crossing', indicator_col='NON_EXISTENT_COLUMN')
            .build()
        )
        nb.log(f"  Missing column: {len(result_missing.zones)} zones")
    except Exception as e:
        nb.warning(f"  Expected error: {type(e).__name__}: {str(e)[:80]}")
        nb.log(f"  Error handling works ‚úÖ")

nb.substep("11.4: Invalid Parameters")

with nb.error_handling("Invalid params test", critical=False):
    try:
        result_invalid = (
            analyze_zones(df)
            .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
            .detect_zones('zero_crossing', indicator_col='macd_hist', min_duration=-5)  # Invalid
            .build()
        )
    except ValueError as e:
        nb.warning(f"  Expected error: {str(e)[:80]}")
        nb.log(f"  Validation works ‚úÖ")

nb.success("‚úÖ Edge cases handled gracefully!")
```

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- Small datasets (< 50 bars)
- No zones detected case
- Missing indicator columns
- Invalid parameters
- Error handling demonstration

**–°—Å—ã–ª–∫–∏:**
- zonan.md lines 3962-3967 (Edge Cases spec)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 1.7: –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ"

**–¢–µ–∫—É—â–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–í–í–û–î–Ø–¢ –í –ó–ê–ë–õ–£–ñ–î–ï–ù–ò–ï!):**
```python
# Line 6: "–≠—Ç–æ –ò–ó–í–ï–°–¢–ù–´–ô –ë–ê–ì, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ä—É—à–∞–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã."
# Line 10: "–î–µ—Ç–µ–∫—Ü–∏—é –¥–ª—è –¥—Ä—É–≥–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (–±–µ–∑ analyze() –∏–∑-–∑–∞ –±–∞–≥–∞)"
# Line 437: "–ë–ï–ó .analyze() –∏–∑-–∑–∞ –±–∞–≥–∞ –≤ ZoneFeaturesAnalyzer (hardcoded –¥–ª—è MACD)"
# Line 451: ".build()  # –ë–ï–ó .analyze() –∏–∑-–∑–∞ –±–∞–≥–∞"
# Line 485: "–ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è, analyze() –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –£–î–ê–õ–ò–¢–¨ –∏–ª–∏ –û–ë–ù–û–í–ò–¢–¨ –≤—Å–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏:

# Line 6-10: –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞:
'''
Comprehensive –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω (v2.1)

v2.1 UPDATE (2025-10-20):
‚úÖ ZoneFeaturesAnalyzer —Ç–µ–ø–µ—Ä—å –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô (—á–∏—Ç–∞–µ—Ç indicator_context)
‚úÖ .analyze() —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (MACD, RSI, AO, Custom)
‚úÖ Features extraction —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –ª—é–±—ã—Ö oscillators

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
1. –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (MACD, RSI, AO) - v2.1 universality
2. Feature extraction –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
3. Clustering, statistical tests, sequence analysis
4. Migration guide –∏ best practices
5. Performance benchmarks
'''

# Line 437-492: –£–î–ê–õ–ò–¢–¨ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ", –î–û–ë–ê–í–ò–¢–¨ .analyze()
# Line 551-552: –£–î–ê–õ–ò–¢–¨ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ success messages
```

**–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å:**
- –û–±–Ω–æ–≤–∏—Ç—å module docstring (header)
- –£–¥–∞–ª–∏—Ç—å –≤—Å–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ"
- –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ v2.1 universality
- –î–æ–±–∞–≤–∏—Ç—å success messages

---

### **–≠–¢–ê–ü 2: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 03_analysis_new_features.py - Advanced Features**

**–§–∞–π–ª:** `research/notebooks/03_analysis_new_features.py` (693 lines ‚Üí ~700 lines)  
**–í—Ä–µ–º—è:** ~50-60 –º–∏–Ω—É—Ç  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** ‚≠ê‚≠ê‚≠ê CRITICAL

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 2.1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ API

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (lines 31-32, 76-82, 109-110):**
```python
from bquant.indicators.macd import MACDZoneAnalyzer  # ‚ùå Deprecated API
from bquant.analysis.zones import ZoneFeaturesAnalyzer  # ‚úÖ OK, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ

# Step 1
macd_analyzer = MACDZoneAnalyzer(macd_params={'fast': 12, 'slow': 26, 'signal': 9})
result = macd_analyzer.analyze_complete(df)  # ‚ùå Deprecated method

# Step 2
zone_dict = macd_analyzer._zone_to_dict(zone)  # ‚ùå AttributeError: –º–µ—Ç–æ–¥ —É–¥–∞–ª–µ–Ω
features = features_analyzer.extract_zone_features(zone_dict)  # ‚ùå Wrong signature
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –û–ë–ù–û–í–ò–¢–¨ –∏–º–ø–æ—Ä—Ç—ã
from bquant.analysis.zones import analyze_zones, analyze_macd_zones  # ‚úÖ v2.1 API
from bquant.analysis.zones.models import ZoneAnalysisResult  # ‚úÖ v2.1 models

# Step 1: –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ v2.1 API
result = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=True,
        n_clusters=3,
        swing_strategy='find_peaks',  # v2.1: swing —Ä–∞–±–æ—Ç–∞–µ—Ç
        run_hypothesis=True,
        run_regression=True,
        run_validation=True
    )
    .build()
)

nb.success(f"v2.1 API: {len(result.zones)} zones with FULL analysis")

# Step 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å zone.features –Ω–∞–ø—Ä—è–º—É—é
for zone in result.zones[:5]:
    if zone.features:  # ‚úÖ Features —É–∂–µ extracted –ø–æ—Å–ª–µ .analyze()
        peak_time_ratio = zone.features.get('peak_time_ratio')
        trough_time_ratio = zone.features.get('trough_time_ratio')
        
        nb.log(f"  Zone {zone.zone_id} ({zone.type}):")
        nb.log(f"    Peak time ratio: {peak_time_ratio:.3f}" if peak_time_ratio else "    Peak: N/A")
        nb.log(f"    Trough time ratio: {trough_time_ratio:.3f}" if trough_time_ratio else "    Trough: N/A")
```

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å:**
- –ó–∞–º–µ–Ω–∏—Ç—å `MACDZoneAnalyzer` ‚Üí `analyze_zones()` (v2.1 universal API)
- –ó–∞–º–µ–Ω–∏—Ç—å `macd_analyzer.analyze_complete()` ‚Üí builder pattern
- –£–¥–∞–ª–∏—Ç—å `_zone_to_dict()` ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features` –Ω–∞–ø—Ä—è–º—É—é
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π `.analyze()` —Å –≤—Å–µ–º–∏ –æ–ø—Ü–∏—è–º–∏

**–°—Å—ã–ª–∫–∏:**
- zouni_v2.md Phase 1 Task 1.6 (ZoneFeaturesAnalyzer)
- examples/02a_universal_zones.py (v2.1 usage examples)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 2.2: Step 3 - Swing Strategies (Numba crash issue)

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (lines 157-228):**
```python
nb.step("–®–∞–≥ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Swing Strategies (Phase 3.1)")

# –¢–µ—Å—Ç–∏—Ä—É–µ—Ç 3 swing strategies:
# - ZigZagSwingStrategy ‚ùå Numba crash –Ω–∞ Windows
# - FindPeaksSwingStrategy
# - PivotPointsSwingStrategy
```

**–ò–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞:**
- ZigZagSwingStrategy –≤—ã–∑—ã–≤–∞–µ—Ç Numba crash –Ω–∞ Windows (external issue)
- –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ zo_issue_numba_zoneinfo_none.md

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.step("Step 3: Swing Strategies Comparison")

nb.info("Testing different swing detection strategies:")

# FindPeaksSwingStrategy (RECOMMENDED, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –≤—Å–µ—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö)
result_findpeaks = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=False,
        swing_strategy='find_peaks',  # ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ
        swing_params={'height': 0.001, 'prominence': 0.0005}
    )
    .build()
)

nb.log(f"  FindPeaks strategy: {len(result_findpeaks.zones)} zones")

# –ü–æ–∫–∞–∑–∞—Ç—å swing metrics –≤ features
if result_findpeaks.zones and result_findpeaks.zones[0].features:
    swing_metrics = {k: v for k, v in result_findpeaks.zones[0].features.items() if 'swing' in k.lower()}
    nb.log(f"  Swing metrics extracted: {list(swing_metrics.keys())}")

# PivotPointsSwingStrategy
result_pivot = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=False,
        swing_strategy='pivot_points',
        swing_params={'left_bars': 5, 'right_bars': 5}
    )
    .build()
)

nb.log(f"  PivotPoints strategy: {len(result_pivot.zones)} zones")

# ZigZagSwingStrategy - SKIP –Ω–∞ Windows –∏–∑-–∑–∞ Numba issue
nb.warning("  ZigZag strategy SKIPPED (Numba crash on Windows - known external issue)")
nb.log("  See: devref/gaps/zo/zo_issue_numba_zoneinfo_none.md")

nb.success("‚úÖ Swing strategies tested (2/3, ZigZag skipped due to external issue)")
```

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å v2.1 API —Å `swing_strategy='find_peaks'`
- –ü–æ–∫–∞–∑–∞—Ç—å swing metrics –≤ features
- SKIP ZigZagSwingStrategy (Numba issue documented)
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å FindPeaks –∏ PivotPoints

**–°—Å—ã–ª–∫–∏:**
- devref/gaps/zo/zo_issue_numba_zoneinfo_none.md (Numba crash documentation)
- bquant/analysis/zones/strategies/swing/ (swing strategies implementations)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 2.3: Steps 4-9 –∏—Å–ø–æ–ª—å–∑—É—é—Ç _zone_to_dict()

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (–ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –≤ Steps 4-9):**
```python
# Step 4: Divergence
for zone in result.zones[:10]:
    zone_dict = macd_analyzer._zone_to_dict(zone)  # ‚ùå AttributeError
    features = features_analyzer.extract_zone_features(zone_dict)
    divergence = features.has_classic_divergence
```

**–†–µ—à–µ–Ω–∏–µ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –≤—Å–µ—Ö steps):**
```python
# Step 4: Divergence Detection
nb.step("Step 4: Divergence Detection")

nb.info("Testing divergence detection for zones:")

result_with_divergence = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(clustering=False)  # Features –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è
    .build()
)

# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º divergence –∏–∑ features
divergence_count = 0
hidden_div_count = 0

for zone in result_with_divergence.zones:
    if zone.features:
        # Classic divergence
        if zone.features.get('has_classic_divergence'):
            divergence_count += 1
            nb.log(f"  Zone {zone.zone_id}: Classic divergence detected")
        
        # Hidden divergence (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ features)
        if zone.features.get('has_hidden_divergence'):
            hidden_div_count += 1

nb.log(f"  Classic divergences: {divergence_count}/{len(result_with_divergence.zones)}")
nb.log(f"  Hidden divergences: {hidden_div_count}/{len(result_with_divergence.zones)}")

nb.success("‚úÖ Divergence detection works with v2.1 API")
```

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å –≤–æ –í–°–ï–• Steps 4-9:**
- –£–±—Ä–∞—Ç—å `macd_analyzer._zone_to_dict(zone)`
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features` –Ω–∞–ø—Ä—è–º—É—é (—É–∂–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ—Å–ª–µ `.analyze()`)
- –ò–õ–ò –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ features_analyzer (–¥–ª—è custom extraction)

**–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫:**
- Step 4: Divergence Detection
- Step 5: Volatility Analysis
- Step 6: Volume Analysis
- Step 7: Hypothesis Tests (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `result.hypothesis_tests`)
- Step 8: Regression Analysis (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `result.regression` –µ—Å–ª–∏ –µ—Å—Ç—å)
- Step 9: Validation Suite (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `result.validation` –µ—Å–ª–∏ –µ—Å—Ç—å)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 2.4: Hypothesis Tests –≤—ã–∑—ã–≤–∞—é—Ç –Ω–∞–ø—Ä—è–º—É—é

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (lines 413-492):**
```python
nb.step("–®–∞–≥ 7: Hypothesis Tests (Phase 3.7)")

# –°–æ–∑–¥–∞–µ—Ç HypothesisTestSuite –Ω–∞–ø—Ä—è–º—É—é
hypothesis_suite = HypothesisTestSuite()
hypothesis_results = hypothesis_suite.run_all_tests(...)  # ‚ùå –†—É—á–Ω–æ–π –≤—ã–∑–æ–≤
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.step("Step 7: Statistical Hypothesis Tests")

nb.info("v2.1: Hypothesis tests —á–µ—Ä–µ–∑ pipeline:")

result_with_tests = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=True,
        run_hypothesis=True  # ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ pipeline
    )
    .build()
)

# –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
if result_with_tests.hypothesis_tests:
    tests = result_with_tests.hypothesis_tests
    
    nb.log(f"  Hypothesis tests executed")
    nb.log(f"  Data size: {tests.data_size if hasattr(tests, 'data_size') else 'N/A'}")
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if hasattr(tests, 'results') and tests.results:
        passed = sum(1 for r in tests.results.values() if r and hasattr(r, 'p_value') and r.p_value < 0.05)
        nb.log(f"  Significant tests (p < 0.05): {passed}/{len(tests.results)}")
        
        # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–µ—Å—Ç—É
        for test_name, result in tests.results.items():
            if result:
                nb.log(f"    {test_name}: p={getattr(result, 'p_value', 'N/A')}")
    
    nb.success("‚úÖ Hypothesis tests —Ä–∞–±–æ—Ç–∞—é—Ç —á–µ—Ä–µ–∑ pipeline (v2.1)")
else:
    nb.warning("  Insufficient data for hypothesis tests")
```

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `run_hypothesis=True` –≤ `.analyze()`
- –ò–∑–≤–ª–µ–∫–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ `result.hypothesis_tests`
- –ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å HypothesisTestSuite –≤—Ä—É—á–Ω—É—é

**–°—Å—ã–ª–∫–∏:**
- bquant/analysis/zones/analyzer.py (UniversalZoneAnalyzer.analyze_zones method)
- bquant/analysis/statistical/ (HypothesisTestSuite)

---

#### –ü—Ä–æ–±–ª–µ–º–∞ 2.5: Regression & Validation

**–¢–µ–∫—É—â–∏–π –∫–æ–¥ (lines 493-618):**
```python
nb.step("–®–∞–≥ 8: Regression Analysis")
# –°–æ–∑–¥–∞–µ—Ç ZoneRegressionAnalyzer –Ω–∞–ø—Ä—è–º—É—é ‚ùå

nb.step("–®–∞–≥ 9: Validation Suite")
# –°–æ–∑–¥–∞–µ—Ç ValidationSuite –Ω–∞–ø—Ä—è–º—É—é ‚ùå
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
nb.step("Step 8: Regression & Validation")

nb.info("v2.1: Regression –∏ validation —á–µ—Ä–µ–∑ pipeline:")

result_full = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=True,
        run_regression=True,   # ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ pipeline
        run_validation=True    # ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ pipeline
    )
    .build()
)

# Regression results
if hasattr(result_full, 'regression') and result_full.regression:
    nb.log("  Regression analysis available")
    # –ü–æ–∫–∞–∑–∞—Ç—å regression metrics –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã

# Validation results
if hasattr(result_full, 'validation') and result_full.validation:
    nb.log("  Validation analysis available")
    # –ü–æ–∫–∞–∑–∞—Ç—å validation metrics –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã

nb.success("‚úÖ Regression & Validation —á–µ—Ä–µ–∑ unified pipeline")
```

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `run_regression=True`, `run_validation=True` –≤ `.analyze()`
- –ò–∑–≤–ª–µ–∫–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ `result.regression`, `result.validation`
- –ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å analyzers –≤—Ä—É—á–Ω—É—é

---

### **–≠–¢–ê–ü 3: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è**

**–í—Ä–µ–º—è:** ~10 –º–∏–Ω—É—Ç  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** ‚≠ê‚≠ê‚≠ê MANDATORY

---

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ 3.1: –ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö notebooks

```bash
# Test 1: 03_zones_universal.py (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π)
python research/notebooks/03_zones_universal.py --no-trap
Expected: 
- Exit code 0
- All 11 steps complete (–¥–æ–±–∞–≤–ª–µ–Ω Step 11: Edge Cases)
- Features extracted –¥–ª—è MACD, RSI, AO
- Clustering results shown
- Statistical tests shown
- Sequence analysis shown
- NO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –æ "–±–∞–≥–µ"

# Test 2: 03_analysis_new_features.py (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π)
python research/notebooks/03_analysis_new_features.py --no-trap
Expected:
- Exit code 0
- All 10 steps complete
- Time metrics —Ä–∞–±–æ—Ç–∞—é—Ç
- Swing strategies —Ä–∞–±–æ—Ç–∞—é—Ç (FindPeaks, PivotPoints; ZigZag skipped)
- Divergence detection —Ä–∞–±–æ—Ç–∞–µ—Ç
- Volume/Volatility analysis —Ä–∞–±–æ—Ç–∞—é—Ç
- Hypothesis tests —Ä–∞–±–æ—Ç–∞—é—Ç
- Regression —Ä–∞–±–æ—Ç–∞–µ—Ç
- Validation —Ä–∞–±–æ—Ç–∞–µ—Ç
```

**Checklist:**
- [ ] 03_zones_universal.py - exit code 0, 11 steps
- [ ] 03_analysis_new_features.py - exit code 0, 10 steps
- [ ] Features –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (MACD, RSI, AO)
- [ ] Clustering demonstrated
- [ ] Statistical tests demonstrated
- [ ] Sequence analysis demonstrated
- [ ] Swing strategies —Ä–∞–±–æ—Ç–∞—é—Ç (2/3)
- [ ] Divergence/Volume/Volatility —Ä–∞–±–æ—Ç–∞—é—Ç
- [ ] NO —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
- [ ] English output (–¥–ª—è cp1251 compatibility)

---

#### –ü—Ä–æ–≤–µ—Ä–∫–∞ 3.2: Coverage verification

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –í–°–ï v2.1 features –ø–æ–∫—Ä—ã—Ç—ã
grep "clustering=True" research/notebooks/03_zones_universal.py
grep "swing_strategy=" research/notebooks/03_zones_universal.py
grep "zone.features" research/notebooks/03_analysis_new_features.py
grep "volume_indicator_corr" research/notebooks/*.py

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Å—Ç–∞—Ä—ã–π API —É–¥–∞–ª–µ–Ω
grep "_zone_to_dict" research/notebooks/03_analysis_new_features.py
Expected: NO matches (–º–µ—Ç–æ–¥ —É–¥–∞–ª–µ–Ω)

grep "MACDZoneAnalyzer\(" research/notebooks/03_analysis_new_features.py
Expected: NO matches –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö (deprecated)
```

**Checklist:**
- [ ] `.analyze()` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
- [ ] `clustering=True` –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö
- [ ] `swing_strategy=` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
- [ ] `zone.features` –≤–º–µ—Å—Ç–æ `_zone_to_dict()`
- [ ] `volume_indicator_corr` (v2.1 field) —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è
- [ ] NO calls to deprecated methods

---

## üìä –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤

### 03_zones_universal.py - Modification Plan

**–¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (10 steps):**
- Step 1: Data Loading ‚úÖ OK
- Step 2: Universal API Basics ‚úÖ OK
- Step 3: Detection Strategies ‚úÖ OK
- Step 4: Parameter Sensitivity ‚úÖ OK
- Step 5: Zone Statistics ‚Üí **–û–ë–ù–û–í–ò–¢–¨** (add features, clustering, tests)
- Step 6: Modular Usage ‚úÖ OK (minor updates)
- Step 7: Caching & Persistence ‚úÖ OK
- Step 8: Migration Guide ‚úÖ OK
- Step 9: Other Indicators ‚Üí **–û–ë–ù–û–í–ò–¢–¨** (add .analyze(), feature comparison)
- Step 10: Performance ‚úÖ OK
- Step 11: **–î–û–ë–ê–í–ò–¢–¨** (Edge Cases)

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏:**

**1. Module docstring (lines 1-19):**
- –£–¥–∞–ª–∏—Ç—å: *"–ë–ê–ì hardcoded –¥–ª—è MACD"*
- –î–æ–±–∞–≤–∏—Ç—å: *"v2.1 UPDATE: ZoneFeaturesAnalyzer —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π"*
- –î–æ–±–∞–≤–∏—Ç—å: *"–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"*

**2. Step 5 (lines 219-253) ‚Üí –ü–ï–†–ï–ü–ò–°–ê–¢–¨:**
- –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å: "Zone Statistics" ‚Üí "Full Analysis Pipeline Deep Dive"
- –î–æ–±–∞–≤–∏—Ç—å: `.analyze(clustering=True, swing_strategy='find_peaks', ...)`
- –î–æ–±–∞–≤–∏—Ç—å: Feature extraction examples –¥–ª—è MACD
- –î–æ–±–∞–≤–∏—Ç—å: Substep 5.4: Clustering Analysis
- –î–æ–±–∞–≤–∏—Ç—å: Substep 5.5: Statistical Tests
- –î–æ–±–∞–≤–∏—Ç—å: Substep 5.6: Sequence Analysis
- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ: ~50-70 lines

**3. Step 9 (lines 434-492) ‚Üí –ü–ï–†–ï–ü–ò–°–ê–¢–¨:**
- –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å: "Other Indicators - Detection Examples" ‚Üí "Multiple Indicators - Feature Comparison"
- –ò–∑–º–µ–Ω–∏—Ç—å: `.build()` ‚Üí `.analyze(clustering=True).build()` –¥–ª—è RSI –∏ AO
- –î–æ–±–∞–≤–∏—Ç—å: Feature comparison table
- –î–æ–±–∞–≤–∏—Ç—å: Substep 9.1: Zone Overlap Analysis
- –î–æ–±–∞–≤–∏—Ç—å: Substep 9.2: Consensus Signals
- –£–¥–∞–ª–∏—Ç—å: –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ"
- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ: ~30-40 lines

**4. Step 11 ‚Üí –î–û–ë–ê–í–ò–¢–¨ –ø–æ—Å–ª–µ Step 10:**
- –ù–æ–≤—ã–π step: "Edge Cases & Error Handling"
- Substep 11.1: Small Dataset (< 50 bars)
- Substep 11.2: No Zones Detected
- Substep 11.3: Missing Indicator Column
- Substep 11.4: Invalid Parameters
- –ù–æ–≤—ã–µ lines: ~50-60 lines

**–ò—Ç–æ–≥–æ: 412 ‚Üí ~550-580 lines**

---

### 03_analysis_new_features.py - Modification Plan

**–¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (10 steps):**
- Step 1: –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç ‚Üí **–û–ë–ù–û–í–ò–¢–¨** (v2.1 API)
- Step 2: Time Metrics ‚ùå Fails ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (—É–±—Ä–∞—Ç—å _zone_to_dict)
- Step 3: Swing Strategies ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (v2.1 API + skip ZigZag)
- Step 4: Divergence ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (use zone.features)
- Step 5: Volatility ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (use zone.features)
- Step 6: Volume ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (use zone.features)
- Step 7: Hypothesis Tests ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (use result.hypothesis_tests)
- Step 8: Regression ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (use result.regression)
- Step 9: Validation ‚ùå Not reached ‚Üí **–ò–°–ü–†–ê–í–ò–¢–¨** (use result.validation)
- Step 10: –†–µ–∑—é–º–µ ‚ùå Not reached ‚Üí **–û–ë–ù–û–í–ò–¢–¨**

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏:**

**1. Imports (lines 31-43):**
```python
# –£–î–ê–õ–ò–¢–¨:
from bquant.indicators.macd import MACDZoneAnalyzer  # ‚ùå Deprecated

# –ó–ê–ú–ï–ù–ò–¢–¨ –Ω–∞:
from bquant.analysis.zones import analyze_zones  # ‚úÖ v2.1 universal API
from bquant.analysis.zones.models import ZoneAnalysisResult

# –û–°–¢–ê–í–ò–¢–¨ (–¥–ª—è advanced testing):
from bquant.analysis.zones import ZoneFeaturesAnalyzer  # ‚úÖ –î–ª—è custom extraction
from bquant.analysis.statistical import HypothesisTestSuite  # ‚úÖ OK
# ... rest of strategy imports
```

**2. Step 1 (lines 54-94) ‚Üí –û–ë–ù–û–í–ò–¢–¨:**
```python
# –ë–´–õ–û:
macd_analyzer = MACDZoneAnalyzer(...)
result = macd_analyzer.analyze_complete(df)

# –°–¢–ê–õ–û:
result = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        clustering=True,
        n_clusters=3,
        swing_strategy='find_peaks',
        run_hypothesis=True,
        run_regression=False,  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        run_validation=False   # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    )
    .build()
)
```

**3. Step 2 (lines 96-156) ‚Üí –ò–°–ü–†–ê–í–ò–¢–¨:**
```python
# –ë–´–õ–û:
zone_dict = macd_analyzer._zone_to_dict(zone)  # ‚ùå AttributeError
features = features_analyzer.extract_zone_features(zone_dict)

# –°–¢–ê–õ–û (–≤–∞—Ä–∏–∞–Ω—Ç 1 - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å zone.features):
for zone in result.zones[:5]:
    if zone.features:  # ‚úÖ –£–∂–µ extracted –ø–æ—Å–ª–µ .analyze()
        peak_time_ratio = zone.features.get('peak_time_ratio')
        trough_time_ratio = zone.features.get('trough_time_ratio')
        # ...

# –°–¢–ê–õ–û (–≤–∞—Ä–∏–∞–Ω—Ç 2 - custom extraction):
features_analyzer = ZoneFeaturesAnalyzer(...)
for zone in result.zones[:5]:
    # –ü–µ—Ä–µ–¥–∞–µ–º ZoneInfo –Ω–∞–ø—Ä—è–º—É—é (v2.1 signature)
    zone_data = df.loc[zone.start_index:zone.end_index]
    features = features_analyzer.extract_zone_features(zone, zone_data)
    # ...
```

**4. Steps 3-9 ‚Üí –ü–†–ò–ú–ï–ù–ò–¢–¨ —Ç–æ—Ç –∂–µ –ø–∞—Ç—Ç–µ—Ä–Ω:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features` –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è metrics
- –ò–õ–ò –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ strategy classes –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –£–±—Ä–∞—Ç—å –≤—Å–µ –≤—ã–∑–æ–≤—ã `_zone_to_dict()`

**–ò—Ç–æ–≥–æ: 693 ‚Üí ~700-720 lines (minor changes, mostly API updates)**

---

## üìã Implementation Checklist

### –≠—Ç–∞–ø 1: 03_zones_universal.py (40-50 –º–∏–Ω)

- [ ] **1.1** –û–±–Ω–æ–≤–∏—Ç—å module docstring (—É–¥–∞–ª–∏—Ç—å "–±–∞–≥", –¥–æ–±–∞–≤–∏—Ç—å "v2.1 UPDATE")
- [ ] **1.2** Step 5: –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å "Zone Statistics" ‚Üí "Full Analysis Pipeline Deep Dive"
- [ ] **1.3** Step 5.1: –î–æ–±–∞–≤–∏—Ç—å MACD full analysis —Å `.analyze(clustering=True, swing_strategy='find_peaks')`
- [ ] **1.4** Step 5.2: –ü–æ–∫–∞–∑–∞—Ç—å extracted features (shape, volume, volatility, divergence, swing)
- [ ] **1.5** Step 5.3: –î–æ–±–∞–≤–∏—Ç—å RSI full analysis (proof of universality)
- [ ] **1.6** Step 5.4: –î–æ–±–∞–≤–∏—Ç—å AO full analysis (proof of universality)
- [ ] **1.7** Step 5.5: –î–æ–±–∞–≤–∏—Ç—å Clustering Analysis (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)
- [ ] **1.8** Step 5.6: –î–æ–±–∞–≤–∏—Ç—å Statistical Hypothesis Tests (–ø–æ–∫–∞–∑–∞—Ç—å result.hypothesis_tests)
- [ ] **1.9** Step 5.7: –î–æ–±–∞–≤–∏—Ç—å Sequence Analysis (transitions, patterns)
- [ ] **1.10** Step 9: –û–±–Ω–æ–≤–∏—Ç—å "Other Indicators" ‚Üí "Multiple Indicators - Feature Comparison"
- [ ] **1.11** Step 9: –î–æ–±–∞–≤–∏—Ç—å `.analyze()` –¥–ª—è RSI –∏ AO (–Ω–µ —Ç–æ–ª—å–∫–æ .build())
- [ ] **1.12** Step 9.1: –î–æ–±–∞–≤–∏—Ç—å Zone Overlap Analysis
- [ ] **1.13** Step 9.2: –î–æ–±–∞–≤–∏—Ç—å Consensus Signals
- [ ] **1.14** Step 11: –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π step "Edge Cases & Error Handling"
- [ ] **1.15** Step 11.1-11.4: Small dataset, No zones, Missing column, Invalid params
- [ ] **1.16** –£–¥–∞–ª–∏—Ç—å –í–°–ï –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ "–±–∞–≥–µ" (lines 6, 10, 437, 451, 485, 551-552)
- [ ] **1.17** –ó–∞–º–µ–Ω–∏—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü—É –Ω–∞ English –≤ print statements (–¥–ª—è cp1251 compatibility)
- [ ] **1.18** –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç: `python research/notebooks/03_zones_universal.py --no-trap`

### –≠—Ç–∞–ø 2: 03_analysis_new_features.py (50-60 –º–∏–Ω)

- [ ] **2.1** –û–±–Ω–æ–≤–∏—Ç—å module docstring (–¥–æ–±–∞–≤–∏—Ç—å "v2.1 UPDATE", –æ–ø–∏—Å–∞—Ç—å —á—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è)
- [ ] **2.2** Imports: –ó–∞–º–µ–Ω–∏—Ç—å `MACDZoneAnalyzer` ‚Üí `analyze_zones`
- [ ] **2.3** Step 1: –ó–∞–º–µ–Ω–∏—Ç—å —Å—Ç–∞—Ä—ã–π API –Ω–∞ v2.1 builder pattern
- [ ] **2.4** Step 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `.analyze(clustering=True, swing_strategy='find_peaks', run_hypothesis=True)`
- [ ] **2.5** Step 2 (Time Metrics): –£–±—Ä–∞—Ç—å `_zone_to_dict()` ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features`
- [ ] **2.6** Step 2: –ü–æ–∫–∞–∑–∞—Ç—å peak_time_ratio, trough_time_ratio –∏–∑ zone.features
- [ ] **2.7** Step 3 (Swing): –û–±–Ω–æ–≤–∏—Ç—å –Ω–∞ v2.1 API —Å `swing_strategy=` parameter
- [ ] **2.8** Step 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å FindPeaks –∏ PivotPoints (skip ZigZag - Numba issue)
- [ ] **2.9** Step 3: –ü–æ–∫–∞–∑–∞—Ç—å swing metrics –∏–∑ zone.features
- [ ] **2.10** Step 4 (Divergence): –£–±—Ä–∞—Ç—å `_zone_to_dict()` ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features`
- [ ] **2.11** Step 4: –ü–æ–∫–∞–∑–∞—Ç—å has_classic_divergence, has_hidden_divergence
- [ ] **2.12** Step 5 (Volatility): –£–±—Ä–∞—Ç—å `_zone_to_dict()` ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features`
- [ ] **2.13** Step 5: –ü–æ–∫–∞–∑–∞—Ç—å volatility_expansion, volatility_regime –∏–∑ features
- [ ] **2.14** Step 6 (Volume): –£–±—Ä–∞—Ç—å `_zone_to_dict()` ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `zone.features`
- [ ] **2.15** Step 6: –ü–æ–∫–∞–∑–∞—Ç—å volume_spike_ratio, **volume_indicator_corr** (v2.1 renamed!)
- [ ] **2.16** Step 7 (Hypothesis): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `result.hypothesis_tests` –≤–º–µ—Å—Ç–æ manual suite
- [ ] **2.17** Step 7: –ü–æ–∫–∞–∑–∞—Ç—å test results –∏–∑ pipeline
- [ ] **2.18** Step 8 (Regression): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `result.regression` –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
- [ ] **2.19** Step 9 (Validation): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `result.validation` –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
- [ ] **2.20** Step 10: –û–±–Ω–æ–≤–∏—Ç—å summary —Å v2.1 achievements
- [ ] **2.21** –ó–∞–º–µ–Ω–∏—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü—É –Ω–∞ English –≤ print statements
- [ ] **2.22** –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç: `python research/notebooks/03_analysis_new_features.py --no-trap`

### –≠—Ç–∞–ø 3: Verification & Documentation (10 –º–∏–Ω)

- [ ] **3.1** –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±–∞ notebooks —Å `--no-trap`
- [ ] **3.2** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å exit code 0 –¥–ª—è –æ–±–æ–∏—Ö
- [ ] **3.3** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å–µ steps –∑–∞–≤–µ—Ä—à–µ–Ω—ã
- [ ] **3.4** Grep –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Å–º. Checklist –≤—ã—à–µ)
- [ ] **3.5** –û–±–Ω–æ–≤–∏—Ç—å zonan_v2.md (Stage 2.4 verdict ‚Üí ‚úÖ COMPLETE)
- [ ] **3.6** –û–±–Ω–æ–≤–∏—Ç—å CHANGE_TRACE_LOG_2025-10-20.md
- [ ] **3.7** –û–±–Ω–æ–≤–∏—Ç—å research/notebooks/README.md (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

---

## üìê –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º

### Component 1: Feature Extraction (Shape, Volume, Volatility, Divergence, Swing)

**–ü—Ä–æ–±–ª–µ–º–∞:**
Notebooks –ù–ï –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç feature extraction –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤.

**v2.1 Implementation:**
- `StatisticalShapeStrategy` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç `indicator_col`)
- `StandardVolumeStrategy` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç `indicator_col`, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `volume_indicator_corr`)
- `CombinedVolatilityStrategy` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
- `ClassicDivergenceStrategy` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç `indicator_col`, `indicator_line_col`)
- Swing strategies - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ (FindPeaks, PivotPoints —Ä–∞–±–æ—Ç–∞—é—Ç —Å –ª—é–±—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏)

**–†–µ—à–µ–Ω–∏–µ –≤ notebooks:**

**03_zones_universal.py - Step 5:**
```python
# –î–ª—è –ö–ê–ñ–î–û–ì–û –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ–∫–∞–∑–∞—Ç—å features:

# MACD features
macd_zone = result_macd_full.zones[0]
nb.log("MACD features:")
nb.log(f"  Shape: skewness={macd_zone.features.get('skewness'):.3f}")
nb.log(f"  Volume: volume_indicator_corr={macd_zone.features.get('volume_indicator_corr'):.3f}")  # v2.1!
nb.log(f"  Volatility: expansion={macd_zone.features.get('volatility_expansion'):.3f}")
nb.log(f"  Divergence: classic={macd_zone.features.get('has_classic_divergence')}")
nb.log(f"  Swing: peak_count={macd_zone.features.get('peak_count')}")

# RSI features (PROOF OF UNIVERSALITY!)
rsi_zone = result_rsi_full.zones[0]
nb.log("RSI features:")
nb.log(f"  Shape: skewness={rsi_zone.features.get('skewness'):.3f}")
nb.log(f"  Volume: volume_indicator_corr={rsi_zone.features.get('volume_indicator_corr'):.3f}")  # v2.1!
nb.success("‚úÖ Same features for RSI! TRUE UNIVERSALITY!")

# AO features (PROOF!)
ao_zone = result_ao_full.zones[0]
nb.log("AO features:")
nb.log(f"  Shape: skewness={ao_zone.features.get('skewness'):.3f}")
nb.success("‚úÖ Same features for AO! TRUE UNIVERSALITY!")
```

**03_analysis_new_features.py - Steps 2-6:**
```python
# –ö–∞–∂–¥—ã–π step —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–Ω—É –∫–∞—Ç–µ–≥–æ—Ä–∏—é features –¥–µ—Ç–∞–ª—å–Ω–æ

# Step 2: Time Metrics
for zone in result.zones[:5]:
    peak_time_ratio = zone.features.get('peak_time_ratio')  # ‚úÖ v2.1
    # ... –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑

# Step 4: Divergence
for zone in result.zones[:10]:
    divergence = zone.features.get('has_classic_divergence')  # ‚úÖ v2.1
    # ... –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑

# Step 6: Volume
for zone in result.zones[:10]:
    volume_indicator_corr = zone.features.get('volume_indicator_corr')  # ‚úÖ v2.1 renamed!
    # ... –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
```

**–°—Å—ã–ª–∫–∏:**
- zouni_v2.md Phase 1 Tasks 1.3-1.5 (Universal strategies)
- bquant/analysis/zones/strategies/

---

### Component 2: Clustering

**–ü—Ä–æ–±–ª–µ–º–∞:**
Clustering —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω, –ù–û –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ notebooks (–≤—Å–µ `.build()` –±–µ–∑ `.analyze()`).

**v2.1 Implementation:**
- `UniversalZoneAnalyzer.analyze_zones()` —Å `perform_clustering=True`
- `ZoneAnalysisResult.clustering` - Dict[int, int] (zone_id ‚Üí cluster_id)

**–†–µ—à–µ–Ω–∏–µ –≤ notebooks:**

**03_zones_universal.py - Step 5.5:**
```python
nb.substep("5.5: Clustering Analysis")

nb.info("Grouping zones by similarity:")

if result_macd_full.clustering:
    clusters = result_macd_full.clustering
    
    nb.log(f"  Clusters created: {len(set(clusters.values()))}")
    nb.log(f"  Zones clustered: {len(clusters)}")
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    cluster_distribution = {}
    for cluster_id in clusters.values():
        cluster_distribution[cluster_id] = cluster_distribution.get(cluster_id, 0) + 1
    
    nb.info("  Distribution:")
    for cluster_id, count in sorted(cluster_distribution.items()):
        nb.log(f"    Cluster {cluster_id}: {count} zones")
    
    # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
    for cluster_id in sorted(set(clusters.values())):
        zones_in_cluster = [z for z in result_macd_full.zones if clusters.get(z.zone_id) == cluster_id]
        
        if zones_in_cluster:
            avg_dur = np.mean([z.duration for z in zones_in_cluster])
            zone_types = [z.type for z in zones_in_cluster]
            bull_pct = sum(1 for t in zone_types if t == 'bull') / len(zone_types) * 100
            
            nb.log(f"    Cluster {cluster_id} characteristics:")
            nb.log(f"      Zones: {len(zones_in_cluster)}")
            nb.log(f"      Avg duration: {avg_dur:.1f} bars")
            nb.log(f"      Bull %: {bull_pct:.1f}%")
    
    nb.success("‚úÖ Clustering helps identify similar zone patterns")
else:
    nb.warning("  Clustering not performed (need more zones)")
```

**–°—Å—ã–ª–∫–∏:**
- bquant/analysis/zones/analyzer.py (clustering implementation)
- zonan.md lines 3939 (clustering spec)

---

### Component 3: Statistical Tests (Hypothesis, Sequence)

**–ü—Ä–æ–±–ª–µ–º–∞:**
- HypothesisTestSuite —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω, –ù–û –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é –≤ 03_analysis_new_features.py
- ZoneSequenceAnalyzer —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω, –ù–û –ù–ï –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è

**v2.1 Implementation:**
- `UniversalZoneAnalyzer` –≤—ã–∑—ã–≤–∞–µ—Ç HypothesisTestSuite –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- `result.hypothesis_tests` - AnalysisResult object
- `result.sequences` - sequence analysis results

**–†–µ—à–µ–Ω–∏–µ –≤ notebooks:**

**03_zones_universal.py - Step 5.6:**
```python
nb.substep("5.6: Statistical Hypothesis Tests")

nb.info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã:")

if result_macd_full.hypothesis_tests:
    tests = result_macd_full.hypothesis_tests
    
    nb.log(f"  Tests executed for {tests.data_size} zones")
    
    if hasattr(tests, 'results') and tests.results:
        nb.info("  Test results:")
        
        for test_name, test_result in tests.results.items():
            if test_result and hasattr(test_result, 'p_value'):
                significance = "significant" if test_result.p_value < 0.05 else "not significant"
                nb.log(f"    {test_name}: p={test_result.p_value:.4f} ({significance})")
        
        nb.success("‚úÖ Statistical validation of zones")
else:
    nb.warning("  Insufficient data for hypothesis tests (need 10+ zones)")

nb.substep("5.7: Sequence Analysis")

nb.info("Zone transitions and patterns:")

if result_macd_full.sequences:
    seq = result_macd_full.sequences
    
    # Transitions
    if hasattr(seq, 'transitions') and seq.transitions:
        nb.info("  Transitions:")
        for trans, count in seq.transitions.items():
            nb.log(f"    {trans}: {count}")
    
    # Patterns
    if hasattr(seq, 'patterns') and seq.patterns:
        nb.log(f"  Patterns detected: {len(seq.patterns)}")
        
        for i, pattern in enumerate(seq.patterns[:3]):
            nb.log(f"    Pattern {i+1}: {pattern}")
    
    nb.success("‚úÖ Sequence analysis reveals zone dynamics")
else:
    nb.warning("  No sequence analysis (need more zones)")
```

**03_analysis_new_features.py - Step 7:**
```python
nb.step("Step 7: Hypothesis Tests via Pipeline")

nb.info("v2.1: Tests –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ .analyze():")

result_with_tests = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(run_hypothesis=True)  # ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    .build()
)

# –ò–∑–≤–ª–µ—á—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
if result_with_tests.hypothesis_tests:
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞
    # ...
```

**–°—Å—ã–ª–∫–∏:**
- bquant/analysis/statistical/hypothesis_testing.py
- bquant/analysis/zones/sequence_analysis.py

---

### Component 4: Swing Strategies

**–ü—Ä–æ–±–ª–µ–º–∞:**
- Swing strategies —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã (ZigZag, FindPeaks, PivotPoints)
- –ù–û ZigZag –≤—ã–∑—ã–≤–∞–µ—Ç Numba crash –Ω–∞ Windows
- –ù–û –ù–ï —Ç–µ—Å—Ç–∏—Ä—É—é—Ç—Å—è –≤ notebooks (–∏–∑-–∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –æ "–±–∞–≥–µ")

**v2.1 Implementation:**
- `swing_strategy='find_peaks'` - —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ ‚úÖ
- `swing_strategy='pivot_points'` - —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ ‚úÖ
- `swing_strategy='zigzag'` - Numba crash –Ω–∞ Windows ‚ö†Ô∏è

**–†–µ—à–µ–Ω–∏–µ:**

**03_zones_universal.py - Step 5:**
```python
# –í–∫–ª—é—á–∏—Ç—å swing –≤ analysis
result = analyze_zones(df).detect_zones(...).analyze(
    swing_strategy='find_peaks',  # ‚úÖ RECOMMENDED
    swing_params={'height': 0.001}
).build()

# –ü–æ–∫–∞–∑–∞—Ç—å swing metrics
if zone.features:
    nb.log(f"  Swing: peak_count={zone.features.get('peak_count')}")
    nb.log(f"  Swing: trough_count={zone.features.get('trough_count')}")
```

**03_analysis_new_features.py - Step 3:**
```python
nb.step("Step 3: Swing Strategies Comparison")

# Test FindPeaks
result_findpeaks = analyze_zones(df).analyze(swing_strategy='find_peaks', ...).build()
nb.log(f"  FindPeaks: {sum(1 for z in result_findpeaks.zones if z.features.get('peak_count', 0) > 0)} zones with swings")

# Test PivotPoints
result_pivot = analyze_zones(df).analyze(swing_strategy='pivot_points', ...).build()
nb.log(f"  PivotPoints: {sum(1 for z in result_pivot.zones if z.features.get('peak_count', 0) > 0)} zones with swings")

# ZigZag - SKIP
nb.warning("  ZigZag SKIPPED (Numba crash on Windows - external issue)")
nb.log("  See: devref/gaps/zo/zo_issue_numba_zoneinfo_none.md")

# Comparison
nb.info("  FindPeaks vs PivotPoints:")
# ... —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
```

**–°—Å—ã–ª–∫–∏:**
- devref/gaps/zo/zo_issue_numba_zoneinfo_none.md (Numba issue documentation)
- bquant/analysis/zones/strategies/swing/

---

### Component 5: Regression & Validation

**–ü—Ä–æ–±–ª–µ–º–∞:**
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã (ZoneRegressionAnalyzer, ValidationSuite)
- –ù–û –≤—ã–∑—ã–≤–∞—é—Ç—Å—è –≤—Ä—É—á–Ω—É—é –≤ 03_analysis_new_features.py
- –ù–û –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)

**v2.1 Implementation:**
- `run_regression=True` –≤ `.analyze()`
- `run_validation=True` –≤ `.analyze()`
- `result.regression` (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
- `result.validation` (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)

**–†–µ—à–µ–Ω–∏–µ:**

**03_analysis_new_features.py - Steps 8-9:**
```python
nb.step("Step 8: Regression Analysis via Pipeline")

nb.info("v2.1: Regression —á–µ—Ä–µ–∑ .analyze():")

result_with_regression = (
    analyze_zones(df)
    .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
    .detect_zones('zero_crossing', indicator_col='macd_hist')
    .analyze(
        run_regression=True,  # ‚úÖ –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–∫–ª—é—á–∏—Ç—å
        run_validation=False
    )
    .build()
)

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
if hasattr(result_with_regression, 'regression') and result_with_regression.regression:
    nb.success("  Regression analysis available")
    # –ü–æ–∫–∞–∑–∞—Ç—å metrics
else:
    nb.warning("  Regression not available (ZoneRegressionAnalyzer not initialized or insufficient data)")

# –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è Validation (Step 9)
```

**–°—Å—ã–ª–∫–∏:**
- bquant/analysis/statistical/regression.py (–µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
- bquant/analysis/validation/suite.py

---

## üéØ Expected Outcomes

### –ü–æ—Å–ª–µ –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞:

**03_zones_universal.py (~550-580 lines, 11 steps):**
- ‚úÖ Step 5: Full Analysis Pipeline (features, clustering, statistical tests, sequence)
- ‚úÖ Step 9: Multi-indicator feature comparison (overlap, consensus)
- ‚úÖ Step 11: Edge cases (small data, no zones, errors)
- ‚úÖ `.analyze()` –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (MACD, RSI, AO)
- ‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è v2.1 universality
- ‚úÖ NO —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –æ "–±–∞–≥–µ"
- ‚úÖ English output (cp1251 compatible)

**03_analysis_new_features.py (~700-720 lines, 10 steps):**
- ‚úÖ All 10 steps —Ä–∞–±–æ—Ç–∞—é—Ç (exit code 0)
- ‚úÖ v2.1 universal API (NO deprecated methods)
- ‚úÖ Time Metrics –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã
- ‚úÖ Swing Strategies –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã (FindPeaks, PivotPoints; ZigZag skipped)
- ‚úÖ Divergence Detection –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞
- ‚úÖ Volume Analysis –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞ (`volume_indicator_corr` v2.1!)
- ‚úÖ Volatility Analysis –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞
- ‚úÖ Hypothesis Tests —á–µ—Ä–µ–∑ pipeline
- ‚úÖ Regression —á–µ—Ä–µ–∑ pipeline (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
- ‚úÖ Validation —á–µ—Ä–µ–∑ pipeline (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
- ‚úÖ English output

**Coverage:**
- ‚úÖ 100% v2.1 features –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã
- ‚úÖ 100% analytical strategies –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã
- ‚úÖ 100% detection strategies –ø–æ–∫—Ä—ã—Ç—ã
- ‚úÖ Multi-indicator universality –¥–æ–∫–∞–∑–∞–Ω–∞
- ‚úÖ Edge cases –ø–æ–∫—Ä—ã—Ç—ã
- ‚úÖ Advanced features –ø–æ–∫—Ä—ã—Ç—ã

---

## üìä Verification Criteria

### –ü–æ—Å–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:

**Functionality:**
- [ ] `python research/notebooks/03_zones_universal.py --no-trap` ‚Üí exit code 0
- [ ] `python research/notebooks/03_analysis_new_features.py --no-trap` ‚Üí exit code 0
- [ ] –í—Å–µ steps –≤ –æ–±–æ–∏—Ö notebooks –∑–∞–≤–µ—Ä—à–µ–Ω—ã –ë–ï–ó errors

**API Usage:**
- [ ] NO calls to deprecated `MACDZoneAnalyzer` (except –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö/–ø—Ä–∏–º–µ—Ä–∞—Ö)
- [ ] NO calls to `_zone_to_dict()` (–º–µ—Ç–æ–¥ —É–¥–∞–ª–µ–Ω)
- [ ] `.analyze()` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (MACD, RSI, AO)
- [ ] `clustering=True` –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö
- [ ] `swing_strategy=` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
- [ ] `zone.features` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é

**v2.1 Features:**
- [ ] `volume_indicator_corr` —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è (v2.1 renamed field)
- [ ] `indicator_context` inspection –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö
- [ ] Features extracted –¥–ª—è RSI, AO (proof of universality)
- [ ] Clustering results –ø–æ–∫–∞–∑–∞–Ω—ã
- [ ] Statistical tests results –ø–æ–∫–∞–∑–∞–Ω—ã
- [ ] Sequence analysis results –ø–æ–∫–∞–∑–∞–Ω—ã

**Output Quality:**
- [ ] English output (cp1251 compatible)
- [ ] NO UnicodeEncodeError
- [ ] NO —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –æ "–±–∞–≥–µ"
- [ ] Clear educational value

---

## üìù Implementation Order

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:**

### Phase 1: Critical Fixes (90 –º–∏–Ω—É—Ç)

1. **03_zones_universal.py - Step 5 update** (30 –º–∏–Ω)
   - –î–æ–±–∞–≤–∏—Ç—å full analysis –¥–ª—è MACD, RSI, AO
   - –ü–æ–∫–∞–∑–∞—Ç—å features, clustering
   - –≠—Ç–∞–ø—ã 1.1-1.9 –∏–∑ Checklist

2. **03_zones_universal.py - Step 9 update** (20 –º–∏–Ω)
   - –î–æ–±–∞–≤–∏—Ç—å feature comparison
   - Zone overlap, consensus signals
   - –≠—Ç–∞–ø—ã 1.10-1.13 –∏–∑ Checklist

3. **03_analysis_new_features.py - API migration** (40 –º–∏–Ω)
   - Steps 1-6: Replace old API ‚Üí v2.1
   - Remove _zone_to_dict(), use zone.features
   - –≠—Ç–∞–ø—ã 2.1-2.15 –∏–∑ Checklist

### Phase 2: Additional Features (30 –º–∏–Ω—É—Ç)

4. **03_zones_universal.py - Step 11** (15 –º–∏–Ω)
   - Edge cases testing
   - –≠—Ç–∞–ø—ã 1.14-1.15 –∏–∑ Checklist

5. **03_analysis_new_features.py - Steps 7-10** (15 –º–∏–Ω)
   - Hypothesis/Regression/Validation —á–µ—Ä–µ–∑ pipeline
   - –≠—Ç–∞–ø—ã 2.16-2.20 –∏–∑ Checklist

### Phase 3: Finalization (20 –º–∏–Ω—É—Ç)

6. **Cleanup & English** (10 –º–∏–Ω)
   - –£–¥–∞–ª–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
   - –ó–∞–º–µ–Ω–∏—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü—É ‚Üí English
   - –≠—Ç–∞–ø—ã 1.16-1.17, 2.21 –∏–∑ Checklist

7. **Verification** (10 –º–∏–Ω)
   - –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±–∞ notebooks
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ–∫–ª–∏—Å—Ç—ã
   - –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
   - –≠—Ç–∞–ø 3 –∏–∑ Checklist

**Total: ~140 –º–∏–Ω—É—Ç (2.5 —á–∞—Å–∞)**

---

## üîó Reference Links

**Specifications:**
- zonan.md lines 3802-3998 (Stage 2.4 original spec)
- zonan.md lines 3935-3976 (Detailed plan for 03_zones_universal.py)
- zouni_v2.md Phase 1 (Universal architecture)

**Implementations:**
- bquant/analysis/zones/zone_features.py (ZoneFeaturesAnalyzer v2.1)
- bquant/analysis/zones/analyzer.py (UniversalZoneAnalyzer)
- bquant/analysis/zones/strategies/ (All analytical strategies)
- bquant/analysis/statistical/ (HypothesisTestSuite)
- bquant/analysis/zones/sequence_analysis.py (ZoneSequenceAnalyzer)

**Examples:**
- examples/02a_universal_zones.py (v2.1 usage patterns)
- tests/integration/test_truly_universal_zones.py (v2.1 proof tests)

**Issues:**
- devref/gaps/zo/zo_issue_numba_zoneinfo_none.md (ZigZag Numba crash)

---

## üìå Summary

**–¶–µ–ª—å:** –û–±–Ω–æ–≤–∏—Ç—å research notebooks –¥–ª—è –ü–û–õ–ù–û–ô –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ v2.1 universal features

**Scope:**
- ‚úÖ Detection pipeline (—É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
- ‚úÖ Analysis pipeline (needs update)
- ‚úÖ Advanced features (needs fix)
- ‚úÖ Multi-indicator universality (needs demonstration)

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ 2/2 notebooks —Ä–∞–±–æ—Ç–∞—é—Ç (exit code 0, –≤—Å–µ steps complete)
- ‚úÖ 100% v2.1 features –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã
- ‚úÖ PROOF: Features work for ALL indicators (not just MACD)
- ‚úÖ Advanced features –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã (swing, divergence, volume, etc)
- ‚úÖ Edge cases –ø–æ–∫—Ä—ã—Ç—ã
- ‚úÖ NO —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
- ‚úÖ English output

**–í—Ä–µ–º—è:** ~140 –º–∏–Ω—É—Ç (2.5 —á–∞—Å–∞) –¥–ª—è –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

**–ì–æ—Ç–æ–≤ –Ω–∞—á–∏–Ω–∞—Ç—å –ø–æ —ç—Ç–∞–ø–∞–º?**

