'''
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö bquant.data.validator

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö:
1.  –í–∞–ª–∏–¥–∞—Ü–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö (–æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è).
2.  –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö.
3.  –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω.
4.  –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.
5.  –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –¥–∞–Ω–Ω—ã—Ö.
'''

from pathlib import Path
import pandas as pd
import numpy as np
import json
import logging

# –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø –î–û –ò–ú–ü–û–†–¢–ê –ú–û–î–£–õ–ï–ô
from bquant.core.logging_config import setup_logging
setup_logging(profile='research')

from bquant.core.nb import NotebookSimulator
from bquant.data.loader import (
    load_ohlcv_data
)
from bquant.data.samples import (
    get_sample_data
)
from bquant.data.validator import (
    validate_ohlcv_data,
    validate_data_completeness,
    validate_price_consistency,
    validate_time_series_continuity,
    validate_statistical_properties
)

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –≤—ã–≤–æ–¥ –¥–ª—è pandas
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 200)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–º—É–ª—è—Ç–æ—Ä
nb = NotebookSimulator("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª—è bquant.data.validator")

# --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ---
nb.step("–®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")

nb.info("–î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ sample-–¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞–¥–∏–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
with nb.error_handling("Loading sample data"):
    nb.info("1.1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ sample-–¥–∞–Ω–Ω—ã–µ:")
    df_sample = get_sample_data('tv_xauusd_1h')
    nb.log(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_sample)} —Å—Ç—Ä–æ–∫ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    nb.log(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞: {list(df_sample.columns)}")

# –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
with nb.error_handling("Creating problematic data"):
    nb.info("1.2. –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    
    # –ö–æ–ø–∏—Ä—É–µ–º sample –¥–∞–Ω–Ω—ã–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—ã
    df_problematic = df_sample.copy()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    df_problematic = pd.concat([df_problematic, df_problematic.iloc[-10:]], ignore_index=False)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    df_problematic.iloc[100:110, df_problematic.columns.get_loc('close')] = np.nan
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (high < low)
    df_problematic.iloc[200:205, df_problematic.columns.get_loc('high')] = 1000  # –ù–∏–∑–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    df_problematic.iloc[200:205, df_problematic.columns.get_loc('low')] = 2000   # –í—ã—Å–æ–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã
    df_problematic.iloc[300:305, df_problematic.columns.get_loc('open')] = -100
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –∏–Ω–¥–µ–∫—Å–µ (—Å–æ–∑–¥–∞–µ–º gaps)
    problematic_dates = df_problematic.index.tolist()
    problematic_dates[400:410] = [pd.Timestamp('2024-01-01') + pd.Timedelta(hours=i) for i in range(400, 410)]
    df_problematic.index = problematic_dates
    
    nb.log(f"–°–æ–∑–¥–∞–Ω–æ {len(df_problematic)} —Å—Ç—Ä–æ–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    nb.log("–î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã: –¥—É–±–ª–∏–∫–∞—Ç—ã, –ø—Ä–æ–ø—É—Å–∫–∏, –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã, gaps –≤ –∏–Ω–¥–µ–∫—Å–µ")

nb.wait()

# --- –®–∞–≥ 2: –û—Å–Ω–æ–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö ---
nb.step("–®–∞–≥ 2: –û—Å–Ω–æ–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö")

nb.info("–§—É–Ω–∫—Ü–∏—è validate_ohlcv_data() - —ç—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –¥–∞–Ω–Ω—ã—Ö.")

# –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Validating correct sample data"):
    nb.info("2.1. –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö sample-–¥–∞–Ω–Ω—ã—Ö:")
    validation_correct = validate_ohlcv_data(df_sample, strict=True)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –í–∞–ª–∏–¥–Ω—ã: {validation_correct['is_valid']}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã: {len(validation_correct['issues'])}")
    nb.log(f"  - –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(validation_correct['warnings'])}")
    
    if validation_correct['issues']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        for issue in validation_correct['issues']:
            nb.warning(f"  - {issue}")
    
    if validation_correct['warnings']:
        nb.info("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
        for warning in validation_correct['warnings']:
            nb.info(f"  - {warning}")
    
    nb.log("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    nb.log(json.dumps(validation_correct['stats'], indent=2, default=str))

# –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Validating problematic data"):
    nb.info("2.2. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    validation_problematic = validate_ohlcv_data(df_problematic, strict=True)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –í–∞–ª–∏–¥–Ω—ã: {validation_problematic['is_valid']}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã: {len(validation_problematic['issues'])}")
    nb.log(f"  - –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(validation_problematic['warnings'])}")
    
    if validation_problematic['issues']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:")
        for issue in validation_problematic['issues']:
            nb.error(f"  - {issue}")
    
    if validation_problematic['warnings']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
        for warning in validation_problematic['warnings']:
            nb.warning(f"  - {warning}")
    
    nb.log("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é:")
    for rec in validation_problematic['recommendations']:
        nb.log(f"  - {rec}")

nb.wait()

# --- –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö ---
nb.step("–®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö")

nb.info("–§—É–Ω–∫—Ü–∏—è validate_data_completeness() –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏ –ø—Ä–æ–ø—É—Å–∫–∏.")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Checking completeness of correct data"):
    nb.info("3.1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    completeness_correct = validate_data_completeness(df_sample)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ü–æ–ª–Ω—ã–µ: {completeness_correct['is_complete']}")
    nb.log(f"  - –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏: {completeness_correct['missing_columns']}")
    nb.log(f"  - –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫: {completeness_correct['insufficient_rows']}")
    
    nb.log("–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:")
    for col, ratio in completeness_correct['missing_data_ratio'].items():
        nb.log(f"  - {col}: {ratio:.2%}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Checking completeness of problematic data"):
    nb.info("3.2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    completeness_problematic = validate_data_completeness(df_problematic)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ü–æ–ª–Ω—ã–µ: {completeness_problematic['is_complete']}")
    nb.log(f"  - –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏: {completeness_problematic['missing_columns']}")
    nb.log(f"  - –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫: {completeness_problematic['insufficient_rows']}")
    
    nb.log("–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º:")
    for col, ratio in completeness_problematic['missing_data_ratio'].items():
        nb.log(f"  - {col}: {ratio:.2%}")
    
    if completeness_problematic['recommendations']:
        nb.log("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–ª–Ω–æ—Ç–µ:")
        for rec in completeness_problematic['recommendations']:
            nb.log(f"  - {rec}")

nb.wait()

# --- –®–∞–≥ 4: –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω ---
nb.step("–®–∞–≥ 4: –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω")

nb.info("–§—É–Ω–∫—Ü–∏—è validate_price_consistency() –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É OHLC —Ü–µ–Ω–∞–º–∏ –∏ –≤—ã—è–≤–ª—è–µ—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Checking price consistency of correct data"):
    nb.info("4.1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    consistency_correct = validate_price_consistency(df_sample)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã: {consistency_correct['is_consistent']}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã —Å —Ü–µ–Ω–∞–º–∏: {len(consistency_correct['price_issues'])}")
    nb.log(f"  - –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏: {len(consistency_correct['logical_errors'])}")
    nb.log(f"  - –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {len(consistency_correct['extreme_values'])}")
    
    if consistency_correct['price_issues']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ü–µ–Ω–∞–º–∏:")
        for issue in consistency_correct['price_issues']:
            nb.warning(f"  - {issue}")
    
    if consistency_correct['logical_errors']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏:")
        for error in consistency_correct['logical_errors']:
            nb.error(f"  - {error}")
    
    if consistency_correct['extreme_values']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        for extreme in consistency_correct['extreme_values']:
            nb.warning(f"  - {extreme}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Checking price consistency of problematic data"):
    nb.info("4.2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    consistency_problematic = validate_price_consistency(df_problematic)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã: {consistency_problematic['is_consistent']}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã —Å —Ü–µ–Ω–∞–º–∏: {len(consistency_problematic['price_issues'])}")
    nb.log(f"  - –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏: {len(consistency_problematic['logical_errors'])}")
    nb.log(f"  - –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {len(consistency_problematic['extreme_values'])}")
    
    if consistency_problematic['price_issues']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ü–µ–Ω–∞–º–∏:")
        for issue in consistency_problematic['price_issues']:
            nb.error(f"  - {issue}")
    
    if consistency_problematic['logical_errors']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏:")
        for error in consistency_problematic['logical_errors']:
            nb.error(f"  - {error}")
    
    if consistency_problematic['extreme_values']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        for extreme in consistency_problematic['extreme_values']:
            nb.warning(f"  - {extreme}")
    
    if consistency_problematic['recommendations']:
        nb.log("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏:")
        for rec in consistency_problematic['recommendations']:
            nb.log(f"  - {rec}")

nb.wait()

# --- –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ ---
nb.step("–®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")

nb.info("–§—É–Ω–∫—Ü–∏—è validate_time_series_continuity() –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, –≤—ã—è–≤–ª—è–µ—Ç gaps –∏ –¥—É–±–ª–∏–∫–∞—Ç—ã.")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Checking time series continuity of correct data"):
    nb.info("5.1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    continuity_correct = validate_time_series_continuity(df_sample, expected_frequency='1H')
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã: {continuity_correct['is_continuous']}")
    nb.log(f"  - –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {continuity_correct['detected_frequency']}")
    nb.log(f"  - Gaps: {len(continuity_correct['gaps'])}")
    nb.log(f"  - –î—É–±–ª–∏–∫–∞—Ç—ã: {len(continuity_correct['duplicates'])}")
    nb.log(f"  - –ù–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã: {len(continuity_correct['irregular_intervals'])}")
    
    if continuity_correct['gaps']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã gaps –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥—É:")
        nb.warning(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(continuity_correct['gaps'])}")
        nb.warning(f"  - –ü–µ—Ä–≤—ã–µ 5: {continuity_correct['gaps'][:5]}")
    
    if continuity_correct['duplicates']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫:")
        nb.warning(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(continuity_correct['duplicates'])}")
        nb.warning(f"  - –ü–µ—Ä–≤—ã–µ 5: {continuity_correct['duplicates'][:5]}")
    
    if continuity_correct['irregular_intervals']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã:")
        nb.warning(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(continuity_correct['irregular_intervals'])}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Checking time series continuity of problematic data"):
    nb.info("5.2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    continuity_problematic = validate_time_series_continuity(df_problematic, expected_frequency='1H')
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã: {continuity_problematic['is_continuous']}")
    nb.log(f"  - –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {continuity_problematic['detected_frequency']}")
    nb.log(f"  - Gaps: {len(continuity_problematic['gaps'])}")
    nb.log(f"  - –î—É–±–ª–∏–∫–∞—Ç—ã: {len(continuity_problematic['duplicates'])}")
    nb.log(f"  - –ù–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã: {len(continuity_problematic['irregular_intervals'])}")
    
    if continuity_problematic['gaps']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã gaps –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥—É:")
        nb.error(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(continuity_problematic['gaps'])}")
        nb.error(f"  - –ü–µ—Ä–≤—ã–µ 5: {continuity_problematic['gaps'][:5]}")
    
    if continuity_problematic['duplicates']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫:")
        nb.error(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(continuity_problematic['duplicates'])}")
        nb.error(f"  - –ü–µ—Ä–≤—ã–µ 5: {continuity_problematic['duplicates'][:5]}")
    
    if continuity_problematic['irregular_intervals']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã:")
        nb.warning(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(continuity_problematic['irregular_intervals'])}")
    
    if continuity_problematic['recommendations']:
        nb.log("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏:")
        for rec in continuity_problematic['recommendations']:
            nb.log(f"  - {rec}")

nb.wait()

# --- –®–∞–≥ 6: –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ ---
nb.step("–®–∞–≥ 6: –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤")

nb.info("–§—É–Ω–∫—Ü–∏—è validate_statistical_properties() –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã—è–≤–ª—è–µ—Ç –≤—ã–±—Ä–æ—Å—ã.")

# –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Analyzing statistical properties of correct data"):
    nb.info("6.1. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    stats_correct = validate_statistical_properties(df_sample)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ö–æ–ª–æ–Ω–∫–∏ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏: {len(stats_correct['outliers'])}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º: {len(stats_correct['distribution_issues'])}")
    
    nb.log("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º:")
    for col, stats in stats_correct['statistics'].items():
        nb.log(f"  - {col}:")
        nb.log(f"    * –°—Ä–µ–¥–Ω–µ–µ: {stats['mean']:.4f}")
        nb.log(f"    * –°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {stats['std']:.4f}")
        nb.log(f"    * –ú–∏–Ω: {stats['min']:.4f}")
        nb.log(f"    * –ú–∞–∫—Å: {stats['max']:.4f}")
        nb.log(f"    * –ê—Å–∏–º–º–µ—Ç—Ä–∏—è: {stats['skewness']:.4f}")
        nb.log(f"    * –≠–∫—Å—Ü–µ—Å—Å: {stats['kurtosis']:.4f}")
    
    if stats_correct['outliers']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –≤—ã–±—Ä–æ—Å—ã:")
        for col, outlier_info in stats_correct['outliers'].items():
            nb.warning(f"  - {col}: {outlier_info['count']} –≤—ã–±—Ä–æ—Å–æ–≤ ({outlier_info['percentage']:.1f}%)")
    
    if stats_correct['distribution_issues']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º:")
        for issue in stats_correct['distribution_issues']:
            nb.warning(f"  - {issue}")

# –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
with nb.error_handling("Analyzing statistical properties of problematic data"):
    nb.info("6.2. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    stats_problematic = validate_statistical_properties(df_problematic)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    nb.log(f"  - –ö–æ–ª–æ–Ω–∫–∏ —Å –≤—ã–±—Ä–æ—Å–∞–º–∏: {len(stats_problematic['outliers'])}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º: {len(stats_problematic['distribution_issues'])}")
    
    if stats_problematic['outliers']:
        nb.error("–ù–∞–π–¥–µ–Ω—ã –≤—ã–±—Ä–æ—Å—ã:")
        for col, outlier_info in stats_problematic['outliers'].items():
            nb.error(f"  - {col}: {outlier_info['count']} –≤—ã–±—Ä–æ—Å–æ–≤ ({outlier_info['percentage']:.1f}%)")
    
    if stats_problematic['distribution_issues']:
        nb.warning("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º:")
        for issue in stats_problematic['distribution_issues']:
            nb.warning(f"  - {issue}")
    
    if stats_problematic['recommendations']:
        nb.log("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º —Å–≤–æ–π—Å—Ç–≤–∞–º:")
        for rec in stats_problematic['recommendations']:
            nb.log(f"  - {rec}")

nb.wait()

# --- –®–∞–≥ 7: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–≥–æ–≥–æ –∏ –º—è–≥–∫–æ–≥–æ —Ä–µ–∂–∏–º–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ---
nb.step("–®–∞–≥ 7: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–≥–æ–≥–æ –∏ –º—è–≥–∫–æ–≥–æ —Ä–µ–∂–∏–º–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")

nb.info("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É strict=True –∏ strict=False –≤ validate_ohlcv_data().")

# –°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
with nb.error_handling("Strict validation mode"):
    nb.info("7.1. –°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (strict=True):")
    validation_strict = validate_ohlcv_data(df_problematic, strict=True)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    nb.log(f"  - –í–∞–ª–∏–¥–Ω—ã: {validation_strict['is_valid']}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã: {len(validation_strict['issues'])}")
    nb.log(f"  - –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(validation_strict['warnings'])}")

# –ú—è–≥–∫–∏–π —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
with nb.error_handling("Soft validation mode"):
    nb.info("7.2. –ú—è–≥–∫–∏–π —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (strict=False):")
    validation_soft = validate_ohlcv_data(df_problematic, strict=False)
    nb.log(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –º—è–≥–∫–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    nb.log(f"  - –í–∞–ª–∏–¥–Ω—ã: {validation_soft['is_valid']}")
    nb.log(f"  - –ü—Ä–æ–±–ª–µ–º—ã: {len(validation_soft['issues'])}")
    nb.log(f"  - –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(validation_soft['warnings'])}")

nb.log("–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏:")
nb.log(f"  - –°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º: {len(validation_strict['issues'])} –ø—Ä–æ–±–ª–µ–º, {len(validation_strict['warnings'])} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
nb.log(f"  - –ú—è–≥–∫–∏–π —Ä–µ–∂–∏–º: {len(validation_soft['issues'])} –ø—Ä–æ–±–ª–µ–º, {len(validation_soft['warnings'])} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
nb.log(f"  - –†–∞–∑–Ω–∏—Ü–∞ –≤ –ø—Ä–æ–±–ª–µ–º–∞—Ö: {len(validation_strict['issues']) - len(validation_soft['issues'])}")
nb.log(f"  - –†–∞–∑–Ω–∏—Ü–∞ –≤ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è—Ö: {len(validation_strict['warnings']) - len(validation_soft['warnings'])}")

nb.wait()

# --- –ó–∞–∫–ª—é—á–µ–Ω–∏–µ ---
nb.step("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ")

nb.info("–ú—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏ –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
nb.log("‚úÖ validate_ohlcv_data() - –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
nb.log("‚úÖ validate_data_completeness() - –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö")
nb.log("‚úÖ validate_price_consistency() - –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–Ω")
nb.log("‚úÖ validate_time_series_continuity() - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
nb.log("‚úÖ validate_statistical_properties() - –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤")

nb.info("–í–∞–ª–∏–¥–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –≤—ã—è–≤–∏–ª –≤—Å–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –Ω–∞–º–∏ –ø—Ä–æ–±–ª–µ–º—ã:")
nb.log("üîç –î—É–±–ª–∏–∫–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö")
nb.log("üîç –ü—Ä–æ–ø—É—Å–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö")
nb.log("üîç –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ OHLC")
nb.log("üîç –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã")
nb.log("üîç Gaps –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥—É")

nb.info("–≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ BQuant –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.")

nb.finish()
