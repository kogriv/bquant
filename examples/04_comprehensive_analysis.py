#!/usr/bin/env python3
"""
BQuant - Comprehensive Zone Analysis Pipeline

–ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω:
1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
2. –†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —á–µ—Ä–µ–∑ IndicatorFactory
3. –î–µ—Ç–µ–∫—Ü–∏—è –∑–æ–Ω —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
4. –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (features, statistics, clustering, sequences)
5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
7. –ú–æ–¥—É–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- BQuant: pip install -e .
"""

import sys
import os
import pandas as pd
import numpy as np

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from bquant.analysis.zones import (
    analyze_zones,
    UniversalZoneAnalyzer,
    ZoneDetectionRegistry,
    ZoneDetectionConfig
)
from bquant.analysis.zones.presets import analyze_macd_zones
from bquant.indicators import IndicatorFactory


def create_comprehensive_data(rows: int = 500) -> pd.DataFrame:
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏."""
    dates = pd.date_range(start='2024-01-01', periods=rows, freq='1H')
    np.random.seed(123)
    
    base = 2000.0
    prices = [base]
    
    for i in range(1, rows):
        # –†–∞–∑–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —Ñ–∞–∑—ã
        if i < 150:  # –¢—Ä–µ–Ω–¥ –≤–≤–µ—Ä—Ö
            trend = 0.003
        elif i < 300:  # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è
            trend = -0.002
        else:  # –ë–æ–∫–æ–≤–∏–∫
            trend = 0.0005 * np.sin(i / 10)
        
        noise = np.random.normal(0, 0.001)
        new_price = prices[-1] * (1 + trend + noise)
        prices.append(max(new_price, 100))
    
    return pd.DataFrame({
        'open': prices,
        'high': [p * 1.01 for p in prices],
        'low': [p * 0.99 for p in prices],
        'close': prices,
        'volume': np.random.uniform(100000, 500000, rows)
    }, index=dates)


def print_section(title: str):
    print(f"\n{'='*80}")
    print(f"  {title}")
    print(f"{'='*80}\n")


def main():
    print_section("Comprehensive Zone Analysis Pipeline")
    
    # ========================================================================
    # 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
    # ========================================================================
    print_section("1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏...")
    df = create_comprehensive_data(rows=500)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –±–∞—Ä–æ–≤")
    print(f"   –ü–µ—Ä–∏–æ–¥: {df.index[0]} - {df.index[-1]}")
    print(f"   –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω: {df['close'].min():.2f} - {df['close'].max():.2f}")
    print(f"   –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100:.2f}%")
    
    # ========================================================================
    # 2. –ü–û–õ–ù–´–ô PIPELINE –° –ö–≠–®–ò–†–û–í–ê–ù–ò–ï–ú
    # ========================================================================
    print_section("2. –ü–æ–ª–Ω—ã–π pipeline: Indicator ‚Üí Detection ‚Üí Analysis")
    
    print("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ pipeline —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º:")
    
    result = (
        analyze_zones(df)
        .with_indicator('custom', 'macd', fast_period=12, slow_period=26, signal_period=9)
        .detect_zones('zero_crossing', 
                     indicator_col='macd_hist',
                     min_duration=3)
        .analyze(
            clustering=True,
            n_clusters=3,
            regression=False,  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            validation=False   # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        )
        .with_cache(enable=True, ttl=3600)
        .build()
    )
    
    print(f"‚úÖ Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω:")
    print(f"   –ó–æ–Ω –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {len(result.zones)}")
    print(f"   Bull –∑–æ–Ω: {sum(1 for z in result.zones if z.type == 'bull')}")
    print(f"   Bear –∑–æ–Ω: {sum(1 for z in result.zones if z.type == 'bear')}")
    print(f"   –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {'–î–∞' if result.clustering else '–ù–µ—Ç'}")
    print(f"   Timestamp: {result.metadata['analysis_timestamp']}")
    
    # ========================================================================
    # 3. –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
    # ========================================================================
    print_section("3. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–æ–Ω:")
    print("-" * 40)
    stats = result.statistics
    if 'total_statistics' in stats:
        total = stats['total_statistics']
        print(f"   –í—Å–µ–≥–æ –∑–æ–Ω: {total.get('total_zones', 0)}")
        print(f"   Bull ratio: {total.get('bull_ratio', 0):.2%}")
        print(f"   Bear ratio: {total.get('bear_ratio', 0):.2%}")
    
    if 'duration_distribution' in stats:
        dur = stats['duration_distribution']['overall']
        print(f"\n   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–æ–Ω:")
        print(f"   - –°—Ä–µ–¥–Ω–µ–µ: {dur['mean']:.1f} –±–∞—Ä–æ–≤")
        print(f"   - –ú–µ–¥–∏–∞–Ω–∞: {dur['median']:.1f} –±–∞—Ä–æ–≤")
        print(f"   - Min/Max: {dur['min']:.0f}/{dur['max']:.0f} –±–∞—Ä–æ–≤")
    
    print("\n–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:")
    print("-" * 40)
    if result.sequence_analysis:
        seq = result.sequence_analysis
        if 'transitions' in seq:
            print(f"   –ü–µ—Ä–µ—Ö–æ–¥–æ–≤: {seq['sequence_summary']['total_transitions']}")
            for trans_type, count in seq['transitions'].items():
                print(f"   - {trans_type}: {count}")
    
    print("\n–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è:")
    print("-" * 40)
    if result.clustering and 'clusters_analysis' in result.clustering:
        clusters = result.clustering['clusters_analysis']
        for cluster_id, cluster_info in clusters.items():
            print(f"   –ö–ª–∞—Å—Ç–µ—Ä {cluster_info['cluster_id']}: "
                  f"{cluster_info['size']} –∑–æ–Ω, "
                  f"dominant type: {cluster_info.get('dominant_type', 'N/A')}")
    
    # ========================================================================
    # 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
    # ========================================================================
    print_section("4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    print("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö:")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é results –µ—Å–ª–∏ –Ω–µ—Ç
    os.makedirs('results', exist_ok=True)
    
    # Pickle - –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result.save('results/comprehensive_analysis.pkl', format='pickle')
    print("   üíæ Pickle (–ø–æ–ª–Ω—ã–π): results/comprehensive_analysis.pkl")
    
    # JSON - –ª–µ–≥–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
    result.save('results/comprehensive_analysis.json', format='json', include_data=False)
    print("   üíæ JSON (–±–µ–∑ –¥–∞–Ω–Ω—ã—Ö): results/comprehensive_analysis.json")
    
    # Parquet - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    result.save('results/comprehensive_analysis.parquet', format='parquet', compress=True)
    print("   üíæ Parquet (—Å–∂–∞—Ç—ã–π): results/comprehensive_analysis.parquet/")
    
    # ========================================================================
    # 5. –ú–û–î–£–õ–¨–ù–û–ï –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï
    # ========================================================================
    print_section("5. –ú–æ–¥—É–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    
    print("–°—Ü–µ–Ω–∞—Ä–∏–π: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –¥–µ—Ç–µ–∫—Ü–∏—é –∑–æ–Ω")
    print("-" * 40)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤—Ä—É—á–Ω—É—é
    macd_ind = IndicatorFactory.create('custom', 'macd', fast_period=10, slow_period=20, signal_period=5)
    macd_data = macd_ind.calculate(df)
    
    df_with_macd = df.copy()
    for col in macd_data.data.columns:
        df_with_macd[col] = macd_data.data[col]
    
    # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –∑–æ–Ω—ã
    detector = ZoneDetectionRegistry.get('zero_crossing')
    config = ZoneDetectionConfig(
        min_duration=5,
        rules={'indicator_col': 'macd_hist'},
        strategy_name='zero_crossing'
    )
    zones_only = detector.detect_zones(df_with_macd, config)
    
    print(f"   –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(zones_only)} –∑–æ–Ω (—Ç–æ–ª—å–∫–æ –¥–µ—Ç–µ–∫—Ü–∏—è)")
    print(f"   –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∑–∂–µ")
    
    # –¢–µ–ø–µ—Ä—å –º–æ–∂–µ–º –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–∏ –∑–æ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ
    analyzer = UniversalZoneAnalyzer()
    zones_analysis = analyzer.analyze_zones(
        zones_only,
        df_with_macd,
        perform_clustering=False
    )
    
    print(f"   –ê–Ω–∞–ª–∏–∑ {len(zones_analysis.zones)} –∑–æ–Ω –∑–∞–≤–µ—Ä—à–µ–Ω")
    
    # ========================================================================
    # 6. –°–†–ê–í–ù–ï–ù–ò–ï –†–ê–ó–ù–´–• –ò–ù–î–ò–ö–ê–¢–û–†–û–í
    # ========================================================================
    print_section("6. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
    
    print("–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑–Ω—ã–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏:")
    print("-" * 40)
    
    # MACD
    result_macd = analyze_macd_zones(df, fast=12, slow=26, signal=9, clustering=False)
    print(f"   MACD: {len(result_macd.zones)} –∑–æ–Ω")
    
    # RSI
    from bquant.analysis.zones.presets import analyze_rsi_zones
    result_rsi = analyze_rsi_zones(df, period=14, upper_threshold=70, lower_threshold=30, clustering=False)
    print(f"   RSI: {len(result_rsi.zones)} –∑–æ–Ω")
    
    # AO
    from bquant.analysis.zones.presets import analyze_ao_zones
    result_ao = analyze_ao_zones(df, fast=5, slow=34, clustering=False)
    print(f"   AO: {len(result_ao.zones)} –∑–æ–Ω")
    
    print("\n   üí° –†–∞–∑–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞—Ö–æ–¥—è—Ç —Ä–∞–∑–Ω—ã–µ –∑–æ–Ω—ã!")
    print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    # ========================================================================
    # 7. –ó–ê–ì–†–£–ó–ö–ê –ò –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –†–ê–ë–û–¢–´
    # ========================================================================
    print_section("7. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞:")
    
    from bquant.analysis.zones.models import ZoneAnalysisResult
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ pickle
    loaded_result = ZoneAnalysisResult.load('results/comprehensive_analysis.pkl')
    
    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ —Ñ–∞–π–ª–∞:")
    print(f"   –ó–æ–Ω: {len(loaded_result.zones)}")
    print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {'–î–∞' if loaded_result.statistics else '–ù–µ—Ç'}")
    print(f"   –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {'–î–∞' if loaded_result.clustering else '–ù–µ—Ç'}")
    
    print("\n   –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É:")
    print("   - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: loaded_result.visualize('overview')")
    print("   - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    print("   - –≠–∫—Å–ø–æ—Ä—Ç –≤ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã")
    
    # ========================================================================
    # –ò–¢–û–ì–ò
    # ========================================================================
    print_separator("–ò—Ç–æ–≥–∏ comprehensive analysis")
    
    print("‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ:")
    print("   1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏")
    print("   2. –ü–æ–ª–Ω—ã–π pipeline: indicator ‚Üí detection ‚Üí analysis")
    print("   3. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∫–ª–∞—Å—Ç–µ—Ä—ã)")
    print("   4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ 3 —Ñ–æ—Ä–º–∞—Ç–∞—Ö (pickle, JSON, parquet)")
    print("   5. –ú–æ–¥—É–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    print("   6. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
    print("   7. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")
    
    print("\nüéØ –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
    print("   - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å: –æ–¥–∏–Ω API –¥–ª—è –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
    print("   - –ì–∏–±–∫–æ—Å—Ç—å: –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    print("   - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ")
    print("   - –ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã")
    print("   - –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    print("\nüìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:")
    print("   - examples/02_macd_zone_analysis.py - –±–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä MACD")
    print("   - examples/02a_universal_zones.py - –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
    print("   - research/notebooks/03_zones_universal.py - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ")
    print("   - devref/gaps/zo/zomodul.md - –º–æ–¥—É–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ")
    print("   - devref/gaps/zo/zonan.md - –ø–æ–ª–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞")
    
    print("\n" + "="*80)


def print_separator(title: str):
    print(f"\n{'='*80}")
    print(f"  {title}")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
